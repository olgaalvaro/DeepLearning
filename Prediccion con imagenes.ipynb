{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prediccion con imagenes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7OR9pBpPl1_T","colab_type":"text"},"source":["# **Práctica Deep Learning**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hnwq6XhLmMsi","colab_type":"text"},"source":["Predicción del precio de las habitaciones de AirBnb utilizando todas las **imágenes** disponibles del dataset airbnb mediante:\n","\n","*   Regresión\n","*   Clasificación\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vRL-iZOtq-Bq","colab_type":"text"},"source":["#### **Cargar las librerías y funciones necesarias**"]},{"cell_type":"code","metadata":{"id":"qdFcz8lk9i-E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592830229252,"user_tz":-120,"elapsed":632,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"aaa50ebc-1182-4f60-d13a-f410dd9d73af"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yIxUgWsq9pSL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592830235519,"user_tz":-120,"elapsed":4751,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"84e1ff72-a636-436e-9e93-8fa54b0e977f"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S-KzXCrRrDc6","colab_type":"code","colab":{}},"source":["# Cargamos librerías necesarias\n","import numpy  as np  \n","import pandas as pd\n","\n","import matplotlib.pyplot as plt # para dibujar\n","%matplotlib inline\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Tratamiento de imágenes\n","import imageio as io\n","import cv2\n","\n","# Sets the value of the specified option\n","# Para visualizar la información de todas las filas pj dtypes o head().T aplico set_option en max_rows \n","pd.set_option('display.max_rows', None)\n","# Para visualizar la información de la matriz de correlación\n","pd.set_option('display.max_columns', None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNa_7poCrHJb","colab_type":"code","colab":{}},"source":["# Función que realiza comprobaciones sobre una columna de un dataframe\n","def check_column(df, col_name):\n","    values_unique = len(df[col_name].unique())\n","    values_nan = df[col_name].isnull().sum()\n","    portmissing = round((df[col_name].isnull().sum()/len(df))*100, 4)\n","    \n","    print (f'{col_name} consta de: {values_unique} valores distintos de un total de {len(df)}')\n","    print (f'{col_name} consta de: {values_nan} valores ausentes, {portmissing}%')\n","    \n","    df[col_name].value_counts().head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L3s2M6qVP58G","colab":{}},"source":["# esta es la función que se descargará la imagen y devolverá la imagen y el \n","# índice indicando la posición donde se incrustará la imagen en nuestro array\n","def get_image(data_url, target_size=(224, 224)):\n","    idx, url = data_url\n","    try:\n","        img = io.imread(url)\n","        # hay alguna imagen en blanco y negro y daría error al incluirla en \n","        # nuestro array de imagenes que tiene 3 canales, así que convertimos\n","        # todas las imágenes que tengan menos de 3 dimensiones a color\n","        if img.ndim < 3:\n","            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","        img = cv2.resize(img, dsize=target_size)\n","        return img, idx\n","    except IOError as err:\n","        return (None, idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fbU1hsN3isED","colab_type":"code","colab":{}},"source":["# Función que define la red MLP Multi-Layer Perceptron\n","# parámetro regress = True para problema de regresión con función de activación linear (sin función de activación) y 1 neurona\n","# parámetro regress = False para problema de clasificación con función de activación softmax indicando el nº de clases de la variable objetivo y este valor será el nº de neuronas \n","from tensorflow.keras.models import Sequential#, Model\n","from tensorflow.keras.layers import Dense#, BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, , Flatten, Input\n","\n","def create_mlp(dim, regress):\n","\t# define our MLP network\n","\tmodel = Sequential()\n","\tmodel.add(Dense(32, input_dim=dim, activation='relu'))\n","\tmodel.add(Dense(18, activation='relu'))\n","\tmodel.add(Dense(4, activation='relu'))\n","\t# check to see if the regression node should be added with function activation linear\n","\t# otherwise (classification) use softmax with the number of classes\n","\tif regress:\n","\t\tmodel.add(Dense(1, activation=\"linear\"))\n","\telse:\n","\t\tmodel.add(Dense(5, activation=\"softmax\"))  \n","  \n","\t# return our model\n","\treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Dzd_XDH6OS9u"},"source":["#### **Cargar Dataset airbnb**"]},{"cell_type":"code","metadata":{"id":"bR2y8XFHOyB-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1592830276016,"user_tz":-120,"elapsed":20181,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"366075a8-629e-45fe-c30c-73ac02986a65"},"source":["# Montamos GDrive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZVteTbpOZ22","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592830281555,"user_tz":-120,"elapsed":2243,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"46e468fd-5b6a-49c5-de79-772746212dfe"},"source":["# Read a dot comma-separated values (csv) file into DataFrame called df_airbnb\n","df_airbnb = pd.read_csv('/content/drive/My Drive/airbnb_listings.csv', sep=';', decimal='.')   \n","\n","print(f'Dimensiones del dataframe df_airbnb son: {df_airbnb.shape[0]} filas y {df_airbnb.shape[1]} columnas')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones del dataframe df_airbnb son: 14780 filas y 89 columnas\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bSwraToqOJ3d"},"source":["### **Tratamiento de las imágenes**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XVwxeSUAOJ3h"},"source":["\n","\n","```\n","Análisis de las variables URL\n","\n","    Listing Url: URL del alojamiento\n","    Thumbnail Url: URL miniatura\n","    Medium Url: URL tamaño medio\n","    Picture Url: Url descarga foto\n","    XL Picture Url: URL tamaño grande\n","    Host URL: URL del anfitrión o host\n","    Host Thumbnail Url: URL foto del host tamaño miniatura\n","    Host Picture  Url: URL foto del host tamaño medio\n","```\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1uys1Tf6OJ3j","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1592818597818,"user_tz":-120,"elapsed":869,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"1c19120c-cf3a-44e0-c048-a4fcb2a7d97b"},"source":["# Análisis de las variables URL para el tratamiento de las imágenes\n","check_column(df_airbnb, 'Listing Url') \n","\n","check_column(df_airbnb, 'Thumbnail Url') \n","check_column(df_airbnb, 'Medium Url')\n","check_column(df_airbnb, 'Picture Url') \n","check_column(df_airbnb, 'XL Picture Url')\n","\n","check_column(df_airbnb, 'Host URL') \n","\n","check_column(df_airbnb, 'Host Thumbnail Url') \n","check_column(df_airbnb, 'Host Picture Url') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Listing Url consta de: 14780 valores distintos de un total de 14780\n","Listing Url consta de: 0 valores ausentes, 0.0%\n","Thumbnail Url consta de: 11958 valores distintos de un total de 14780\n","Thumbnail Url consta de: 2820 valores ausentes, 19.0798%\n","Medium Url consta de: 11958 valores distintos de un total de 14780\n","Medium Url consta de: 2820 valores ausentes, 19.0798%\n","Picture Url consta de: 14758 valores distintos de un total de 14780\n","Picture Url consta de: 19 valores ausentes, 0.1286%\n","XL Picture Url consta de: 11958 valores distintos de un total de 14780\n","XL Picture Url consta de: 2820 valores ausentes, 19.0798%\n","Host URL consta de: 8935 valores distintos de un total de 14780\n","Host URL consta de: 0 valores ausentes, 0.0%\n","Host Thumbnail Url consta de: 8894 valores distintos de un total de 14780\n","Host Thumbnail Url consta de: 3 valores ausentes, 0.0203%\n","Host Picture Url consta de: 8894 valores distintos de un total de 14780\n","Host Picture Url consta de: 3 valores ausentes, 0.0203%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CNwRLxP7OJ3v","colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"status":"ok","timestamp":1592818602505,"user_tz":-120,"elapsed":631,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"edfc099e-f1d2-41a7-af35-35b7f05fd639"},"source":["# Dataframe con las imágenes \n","df_urls = df_airbnb.loc[:, 'Thumbnail Url':'XL Picture Url' ]\n","print(f'Dimensiones datos entrenamiento son: {df_urls.shape}')\n","df_urls.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones datos entrenamiento son: (14780, 4)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Thumbnail Url</th>\n","      <th>Medium Url</th>\n","      <th>Picture Url</th>\n","      <th>XL Picture Url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://a0.muscache.com/im/pictures/cffe393a-0...</td>\n","      <td>https://a0.muscache.com/im/pictures/cffe393a-0...</td>\n","      <td>https://public.opendatasoft.com/api/v2/catalog...</td>\n","      <td>https://a0.muscache.com/im/pictures/cffe393a-0...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://a0.muscache.com/im/pictures/ea919e56-a...</td>\n","      <td>https://a0.muscache.com/im/pictures/ea919e56-a...</td>\n","      <td>https://public.opendatasoft.com/api/v2/catalog...</td>\n","      <td>https://a0.muscache.com/im/pictures/ea919e56-a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://a0.muscache.com/im/pictures/57011236/e...</td>\n","      <td>https://a0.muscache.com/im/pictures/57011236/e...</td>\n","      <td>https://public.opendatasoft.com/api/v2/catalog...</td>\n","      <td>https://a0.muscache.com/im/pictures/57011236/e...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       Thumbnail Url  \\\n","0  https://a0.muscache.com/im/pictures/cffe393a-0...   \n","1  https://a0.muscache.com/im/pictures/ea919e56-a...   \n","2  https://a0.muscache.com/im/pictures/57011236/e...   \n","\n","                                          Medium Url  \\\n","0  https://a0.muscache.com/im/pictures/cffe393a-0...   \n","1  https://a0.muscache.com/im/pictures/ea919e56-a...   \n","2  https://a0.muscache.com/im/pictures/57011236/e...   \n","\n","                                         Picture Url  \\\n","0  https://public.opendatasoft.com/api/v2/catalog...   \n","1  https://public.opendatasoft.com/api/v2/catalog...   \n","2  https://public.opendatasoft.com/api/v2/catalog...   \n","\n","                                      XL Picture Url  \n","0  https://a0.muscache.com/im/pictures/cffe393a-0...  \n","1  https://a0.muscache.com/im/pictures/ea919e56-a...  \n","2  https://a0.muscache.com/im/pictures/57011236/e...  "]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"addv5HK8OJ34","colab":{"base_uri":"https://localhost:8080/","height":196},"executionInfo":{"status":"ok","timestamp":1592818605384,"user_tz":-120,"elapsed":553,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"0f7b29f4-ac0f-4409-a9ed-14e4d75c46b7"},"source":["# Incluimos en el df de las imágenes la variable Listing Url\n","df_urls['Listing Url'] = df_airbnb['Listing Url']\n","print(f'Dimensiones del dataframe df_urls son: {df_urls.shape}')\n","df_urls.head(3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones del dataframe df_urls son: (14780, 5)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Thumbnail Url</th>\n","      <th>Medium Url</th>\n","      <th>Picture Url</th>\n","      <th>XL Picture Url</th>\n","      <th>Listing Url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://a0.muscache.com/im/pictures/cffe393a-0...</td>\n","      <td>https://a0.muscache.com/im/pictures/cffe393a-0...</td>\n","      <td>https://public.opendatasoft.com/api/v2/catalog...</td>\n","      <td>https://a0.muscache.com/im/pictures/cffe393a-0...</td>\n","      <td>https://www.airbnb.com/rooms/12768616</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://a0.muscache.com/im/pictures/ea919e56-a...</td>\n","      <td>https://a0.muscache.com/im/pictures/ea919e56-a...</td>\n","      <td>https://public.opendatasoft.com/api/v2/catalog...</td>\n","      <td>https://a0.muscache.com/im/pictures/ea919e56-a...</td>\n","      <td>https://www.airbnb.com/rooms/1629146</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://a0.muscache.com/im/pictures/57011236/e...</td>\n","      <td>https://a0.muscache.com/im/pictures/57011236/e...</td>\n","      <td>https://public.opendatasoft.com/api/v2/catalog...</td>\n","      <td>https://a0.muscache.com/im/pictures/57011236/e...</td>\n","      <td>https://www.airbnb.com/rooms/4539828</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       Thumbnail Url  \\\n","0  https://a0.muscache.com/im/pictures/cffe393a-0...   \n","1  https://a0.muscache.com/im/pictures/ea919e56-a...   \n","2  https://a0.muscache.com/im/pictures/57011236/e...   \n","\n","                                          Medium Url  \\\n","0  https://a0.muscache.com/im/pictures/cffe393a-0...   \n","1  https://a0.muscache.com/im/pictures/ea919e56-a...   \n","2  https://a0.muscache.com/im/pictures/57011236/e...   \n","\n","                                         Picture Url  \\\n","0  https://public.opendatasoft.com/api/v2/catalog...   \n","1  https://public.opendatasoft.com/api/v2/catalog...   \n","2  https://public.opendatasoft.com/api/v2/catalog...   \n","\n","                                      XL Picture Url  \\\n","0  https://a0.muscache.com/im/pictures/cffe393a-0...   \n","1  https://a0.muscache.com/im/pictures/ea919e56-a...   \n","2  https://a0.muscache.com/im/pictures/57011236/e...   \n","\n","                             Listing Url  \n","0  https://www.airbnb.com/rooms/12768616  \n","1   https://www.airbnb.com/rooms/1629146  \n","2   https://www.airbnb.com/rooms/4539828  "]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uAQEuhFsOJ3_","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1592818611745,"user_tz":-120,"elapsed":608,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"4e23ed1f-4416-4a26-bdcf-21368fa8a017"},"source":["print('Thumbnail Url: ', df_urls['Thumbnail Url'][1])\n","print('Medium Url   : ', df_urls['Medium Url'][1])\n","print('Picture Url  : ', df_urls['Picture Url'][1])\n","print('XL Picture Url: ', df_urls['XL Picture Url'][1])\n","print('Listing Url: ', df_urls['Listing Url'][1])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thumbnail Url:  https://a0.muscache.com/im/pictures/ea919e56-aa99-4d5d-a129-1edf0d117d6a.jpg?aki_policy=small\n","Medium Url   :  https://a0.muscache.com/im/pictures/ea919e56-aa99-4d5d-a129-1edf0d117d6a.jpg?aki_policy=medium\n","Picture Url  :  https://public.opendatasoft.com/api/v2/catalog/datasets/airbnb-listings/files/4b3f714036f61061b857571fa1dbfa8f\n","XL Picture Url:  https://a0.muscache.com/im/pictures/ea919e56-aa99-4d5d-a129-1edf0d117d6a.jpg?aki_policy=x_large\n","Listing Url:  https://www.airbnb.com/rooms/1629146\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Drd1yP3TOJ4G","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1592818619075,"user_tz":-120,"elapsed":5312,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"493414d3-dca2-46e8-fade-567859aa0e40"},"source":["print('Thumbnail Url: ', df_urls['Thumbnail Url'][22])\n","print('Medium Url   : ', df_urls['Medium Url'][22])\n","print('Picture Url  : ', df_urls['Picture Url'][22])\n","print('XL Picture Url: ', df_urls['XL Picture Url'][22])\n","print('Listing Url: ', df_urls['Listing Url'][22])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thumbnail Url:  https://a0.muscache.com/im/pictures/a4322298-d93c-48d7-acf2-ca7b27f27e84.jpg?aki_policy=small\n","Medium Url   :  https://a0.muscache.com/im/pictures/a4322298-d93c-48d7-acf2-ca7b27f27e84.jpg?aki_policy=medium\n","Picture Url  :  https://public.opendatasoft.com/api/v2/catalog/datasets/airbnb-listings/files/2b04f7a9d4d4cc75fe300ef2d0f5d8d2\n","XL Picture Url:  https://a0.muscache.com/im/pictures/a4322298-d93c-48d7-acf2-ca7b27f27e84.jpg?aki_policy=x_large\n","Listing Url:  https://www.airbnb.com/rooms/13841176\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"n4nIKukNOJ4R"},"source":["\n","\n","```\n","    Observamos que las imagenes jpg referenciadas en las variables Thumbnail Url, Medium Url y XL Picture Url son las mismas, unicamente cambia \n","    el parámetro aki_policy de small, medium y x_large respectivamente. Trabajaremos con la variable Thumbnail Url puesto que las imágenes son \n","    de menor dimensión.\n","    Picture Url descarga una imagen jpg dimensiones 639*426 y 96 resolución\n","    Listing Url nos redirige en ocasiones al home de airbnb https://www.airbnb.es/s/homes y en otros casos a la url del alojamiento donde \n","    observamos la posibilidad de descargarnos más fotos\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"62d8_UneHeGk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1592830297708,"user_tz":-120,"elapsed":588,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"6bc695ed-07a6-4508-c1e6-f0b342a4f10f"},"source":["# Eliminamos los registros ausentes de la variable Thumbnail Url para trabajar con muestras con imágenes\n","df_airbnb.dropna(subset=['Thumbnail Url'], inplace=True)\n","print(f'Dimensiones datos df_airbnb con valores en la columna Thumbnail Url son: {df_airbnb.shape}')\n","check_column(df_airbnb, 'Thumbnail Url')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones datos df_airbnb con valores en la columna Thumbnail Url son: (11960, 89)\n","Thumbnail Url consta de: 11957 valores distintos de un total de 11960\n","Thumbnail Url consta de: 0 valores ausentes, 0.0%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h57YI11bOJ4R"},"source":["**Proceso de carga de las imágenes en un array con la url y el índice correspondiente**\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tVh7WAYvOJ4U","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1592818883223,"user_tz":-120,"elapsed":635,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"1e67919e-a7c3-4a9a-c499-8340a43161fd"},"source":["# Creamos nuestra estructura de datos, que va a consistir en la url de la\n","# imagen y un índice para saber donde insertarla en nuestro array\n","images_paths = [[i, img_url] for i, img_url in enumerate(df_airbnb['Thumbnail Url'])]\n","print(f'Dimensiones del array de imágenes son: {len(images_paths)}')\n","\n","# visualizamos los 5 primeros registros\n","images_paths[0:5]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones del array de imágenes son: 11960\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[[0,\n","  'https://a0.muscache.com/im/pictures/cffe393a-0d84-4fd5-ab4c-a62e067c1b0d.jpg?aki_policy=small'],\n"," [1,\n","  'https://a0.muscache.com/im/pictures/ea919e56-aa99-4d5d-a129-1edf0d117d6a.jpg?aki_policy=small'],\n"," [2,\n","  'https://a0.muscache.com/im/pictures/57011236/eea5c213_original.jpg?aki_policy=small'],\n"," [3,\n","  'https://a0.muscache.com/im/pictures/974f0245-55c2-4e8c-b9bf-14c1c975c798.jpg?aki_policy=small'],\n"," [4,\n","  'https://a0.muscache.com/im/pictures/c2dde263-20dd-43af-8c6b-be636c2c0ce1.jpg?aki_policy=small']]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sFxkZ9JWOJ4X","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592818889400,"user_tz":-120,"elapsed":1517,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"4c3c1b67-5b4b-4451-bcf7-56db1b9d8659"},"source":["# en este array iremos incrustando las imágenes conforme las vayamos obteniendo\n","loaded_images = np.zeros((len(images_paths), 224, 224, 3), dtype=np.uint8)\n","\n","# y en este array llevaremos un control de cuales se han cargado correctamente y cuales no\n","was_loaded = np.zeros(len(images_paths))\n","\n","print(f'Dimensiones del array de loaded_images son: {loaded_images.shape}')\n","print(f'Dimensiones del array de was_loaded son: {was_loaded.shape}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones del array de loaded_images son: (11960, 224, 224, 3)\n","Dimensiones del array de was_loaded son: (11960,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xRSAOVtGOJ4a","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1592821038666,"user_tz":-120,"elapsed":2145856,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"d5daa133-8f88-4453-d501-0f283059d6a9"},"source":["# Lo ejecutmos una sola vez\n","import concurrent\n","from tqdm import tqdm\n","\n","# creamos un pool de procesos que se irán descargando las imágenes\n","# por defecto, se crearán tantos como CPUs tenga vuestra máquina\n","with concurrent.futures.ProcessPoolExecutor() as executor:\n","    # procesamos la lista de urls de imágenes paralelizandola con el pool de procesos\n","    for (img, idx) in tqdm(executor.map(get_image, images_paths), total=len(images_paths)):\n","        # metemos la imagen en nuestro array\n","        if img is not None:\n","            loaded_images[idx] = img\n","            was_loaded[idx] = 1\n","        else:\n","            was_loaded[idx] = 0\n","\n","print('Terminado!')\n","print(f'Total de imágenes recuperadas correctamente: {sum(was_loaded)}/{len(images_paths)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 11960/11960 [35:43<00:00,  5.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Terminado!\n","Total de imágenes recuperadas correctamente: 11942.0/11960\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"J21El30RKWMK","colab_type":"text"},"source":["\n","\n","```\n","100%|██████████| 11960/11960 [35:43<00:00,  5.58it/s]Terminado!\n","Total de imágenes recuperadas correctamente: 11942.0/11960\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VRVR3M-HSs8T","colab_type":"text"},"source":["**Descarga de las imágenes y procedemos a guardarlas en GDrive para no repetir el proceso**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3cv1LLGeOJ4d","colab":{}},"source":["# Ejecutado 1 sola vez Save NumPy Array to .NPY File (binary)\n","# guardamos las imágenes (y yo os recomiendo que os lo guardéis en GDrive para evitar tener que repetir esto)\n","np.save('images_dropna.npy', loaded_images)\n","np.save('was_loaded_dropna.npy', was_loaded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g6D8yLLfOJ4f","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592818678905,"user_tz":-120,"elapsed":2310,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"61aebd12-7768-4c8e-a8df-a06934088177"},"source":["# montamos GDrive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jTW9-C-1OJ4j","colab":{}},"source":["# almacenamos las imagenes en nuestro drive\n","!cp images_dropna.npy /content/drive/My\\ Drive/images_dropna.npy\n","!cp was_loaded_dropna.npy /content/drive/My\\ Drive/was_loaded_dropna.npy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LxjZDYkZbZT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592821157148,"user_tz":-120,"elapsed":2315,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"f1acf97e-56c3-4c05-bcb4-6a0a42f8b8e9"},"source":["# Comprobar que tenemos los ficheros descargados\n","!ls -lah /content/drive/My\\ Drive/images_dropna.npy /content/drive/My\\ Drive/was_loaded_dropna.npy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-rw------- 1 root root 1.7G Jun 22 10:16 '/content/drive/My Drive/images_dropna.npy'\n","-rw------- 1 root root  94K Jun 22 10:16 '/content/drive/My Drive/was_loaded_dropna.npy'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qvSgnlTVOJ4o","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592830332071,"user_tz":-120,"elapsed":14003,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"cfd27904-dc67-4b69-c779-deb9f3484f25"},"source":["# Cargamos las imágenes de los ficheros salvados en drive\n","loaded_images=np.load('/content/drive/My Drive/images_dropna.npy')\n","was_loaded = np.load('/content/drive/My Drive/was_loaded_dropna.npy')\n","\n","print(f'Dimensiones del array de loaded_images son: {loaded_images.shape}')\n","print(f'Dimensiones del array de was_loaded son: {was_loaded.shape}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones del array de loaded_images son: (11960, 224, 224, 3)\n","Dimensiones del array de was_loaded son: (11960,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_1w9PeHKLPsZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592830346628,"user_tz":-120,"elapsed":1640,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"7e99cf8c-b646-402d-c7ee-91e53c349dda"},"source":["# De las 11960 muestras de airbnb con referencia en la columna Thumbnail URL, se han descargado un total de 11942 imágenes\n","# Nos quedamos exclusivamente con estos datos\n","loaded_images_ok = loaded_images[was_loaded==1]\n","loaded_images_ok.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11942, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"MjtZrR0RLq5u","colab_type":"code","colab":{}},"source":["# Ejecutado 1 sola vez Save NumPy Array to .NPY File (binary)\n","# guardamos las imágenes (y yo os recomiendo que os lo guardéis en GDrive para evitar tener que repetir esto)\n","np.save('loaded_images_ok.npy', loaded_images_ok)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wMZVqPumMDBq","colab_type":"code","colab":{}},"source":["# almacenamos las imagenes en nuestro drive\n","!cp loaded_images_ok.npy /content/drive/My\\ Drive/loaded_images_ok.npy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DV9LI5KEMUrD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592821350592,"user_tz":-120,"elapsed":2593,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"d1e527ae-3f4b-4af1-f90d-019f1d64ceda"},"source":["# Comprobar que tenemos las imágenes descargadas\n","!ls -lah /content/drive/My\\ Drive/loaded_images_ok.npy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-rw------- 1 root root 1.7G Jun 22 10:19 '/content/drive/My Drive/loaded_images_ok.npy'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eb4BWk7Ai8dh","colab_type":"code","colab":{}},"source":["# Recuperar las imágenes descargadas del dataframe airbnb\n","loaded_images_ok = np.load('/content/drive/My Drive/loaded_images_ok.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qRbKUcNqNSxD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592830383228,"user_tz":-120,"elapsed":641,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"4c54fd04-3f51-4a40-ac36-d2970113d25b"},"source":["# Nos quedamos con las muestras del dataset airbnb asociadas a las descarga de imágenes realizada\n","df_airbnb_images = df_airbnb[was_loaded==1]\n","df_airbnb_images.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11942, 89)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"2Hc9q2F-Nqud","colab_type":"code","colab":{}},"source":["# Guardamos el df airbnb con las imágenes\n","df_airbnb_images.to_csv('/content/drive/My Drive/df_airbnb_images_11942.csv', sep=';', decimal='.', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hINNeTCoXDu5","colab_type":"text"},"source":["#### **Cargar el modelo VGG-16**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IQXI0TA7eZjy","colab":{"base_uri":"https://localhost:8080/","height":989},"executionInfo":{"status":"ok","timestamp":1592830395057,"user_tz":-120,"elapsed":3845,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"1e7735a6-646b-43af-cd28-dc0f3d9284cf"},"source":["# Aplicamos el modelo VGG16 para extraer la etapa de extracción de características o FE\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.layers import GlobalAveragePooling2D\n","from keras.models import Model\n","\n","# Modelo VGG16 base con sus pesos  (include_top = True indica que si cargamos la capa de clasificación )  FE+ Flatten + CL\n","model_vgg16 = VGG16(weights=\"imagenet\", include_top=False)\n","\n","# Modelo con la capa GlobalAveragePooling \n","# con la finalidd de convertir los mapas de activacones 2D de la última capa de la etapa de FE a un vector de  nclasses  que \n","# se utiliza para calcular la probabilidad de pertenecer a cada clase\n","x = model_vgg16.output\n","model_gap = GlobalAveragePooling2D()(x)\n","\n","# Modelo resultante\n","model = Model(inputs=model_vgg16.input, outputs=model_gap)\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, None, None, 3)     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2kbroxzRelPo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592821448582,"user_tz":-120,"elapsed":642,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"a6762e9c-ea3b-43af-86eb-b7ad1917c276"},"source":["loaded_images_ok.shape[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11942"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"6jZUysG0_SOs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592821451022,"user_tz":-120,"elapsed":599,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"3080c52e-3619-420d-bfe8-a9f451396476"},"source":["df_airbnb_images.shape[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11942"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FR3sQBmz_QRf","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1592821561334,"user_tz":-120,"elapsed":83823,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"75ff22cd-e0e5-440e-ed59-425a25526750"},"source":["from tqdm import tqdm  \n","from keras.preprocessing.image import img_to_array\n","\n","# Realizamos el procesado de las imágenes para extraer el vector de 512 características\n","images_fe = np.zeros((loaded_images_ok.shape[0], 512))\n","\n","for i in tqdm(range(loaded_images_ok.shape[0])):\n","    img = loaded_images_ok[i]\n","    x = img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","\n","    # Extracción de las características sobre el modelo vgg16 con los pesos de imagenet\n","    features = model.predict(x)\n","    images_fe[i] = features[0]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/11942 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 11942/11942 [01:23<00:00, 143.20it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"aA1J44mgrSOk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592821599932,"user_tz":-120,"elapsed":9213,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"c4927140-3f82-4ecd-97a7-eb0facdfdf9a"},"source":["# Ejecutado 1 sola vez\n","# Save NumPy Array to .NPY File (binary)\n","np.save('features_img_ok.npy', images_fe)\n","# almacenamos las imagenes en nuestro drive\n","!cp features_img_ok.npy /content/drive/My\\ Drive/features_img_ok.npy\n","# Comprobar que tenemos las imágenes descargadas\n","!ls -lah /content/drive/My\\ Drive/features_img_ok.npy\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-rw------- 1 root root 47M Jun 22 10:23 '/content/drive/My Drive/features_img_ok.npy'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ohQMrxIwrv9R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592830410254,"user_tz":-120,"elapsed":1172,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"48d39f5f-66cf-4614-cfb6-3c94a0abfa5b"},"source":["# Cargamos el fichero con las características de las imágenes\n","images_fe=np.load('/content/drive/My Drive/features_img_ok.npy')\n","print(f'Dimensiones del array de images_fe son: {images_fe.shape}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dimensiones del array de images_fe son: (11942, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BW07ohgxe-ex","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592830414705,"user_tz":-120,"elapsed":617,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"e7b7ff4e-bd3a-4692-bd61-87dee45e473c"},"source":["images_fe.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11942, 512)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fO40up8WWaXa"},"source":["#### **Etiqueta de la variable objetivo**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kP6oCB89WaXd","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1592830416941,"user_tz":-120,"elapsed":628,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"2877f0fd-7c6f-48cc-90a8-0aa9c1489a9d"},"source":["# Etiqueta de la variable objetivo para el problema de regresión\n","y =df_airbnb_images['Price']\n","\n","import matplotlib.pyplot as plt\n","plt.hist(y, bins=10)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQUElEQVR4nO3df4xdZZ3H8fdnqYBipK1MGmybnW5sNNXEhW2ghM3GWLcUMJY/0EDM0rDN9o/trmhM3LL7R7MqCSRGhGQlNlItxoBsJUsDrqRbMJv9g8ogBoHKduSHbQN0tAV3NbpWv/vHfQYvdYYy907ntjPvV3Iz53yf59z7PPM0+cw599zbVBWSpLntjwY9AEnS4BkGkiTDQJJkGEiSMAwkScC8QQ+gV+ecc04NDw8PehiSdMp49NFHf1pVQxO1nbJhMDw8zMjIyKCHIUmnjCTPT9bmZSJJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJHEKfwK5H8Ob7x/I6z534+UDeV1JOh7PDCRJhoEkyTCQJPEGwiDJtiSHkjzRVVuYZFeSfe3nglZPkluTjCZ5PMn5Xcesb/33JVnfVf+zJD9sx9yaJNM9SUnS63sjZwZfA9YeU9sM7K6q5cDutg9wKbC8PTYCt0EnPIAtwIXABcCW8QBpff6m67hjX0uSdIIdNwyq6j+Bw8eU1wHb2/Z24Iqu+h3V8TAwP8m5wCXArqo6XFVHgF3A2tb2tqp6uKoKuKPruSRJM6TX9wwWVdULbftFYFHbXgzs7+p3oNVer35ggvqEkmxMMpJkZGxsrMehS5KO1fcbyO0v+pqGsbyR19paVSurauXQ0IT/c5skqQe9hsFL7RIP7eehVj8ILO3qt6TVXq++ZIK6JGkG9RoGO4HxO4LWA/d21a9pdxWtAl5pl5MeANYkWdDeOF4DPNDafp5kVbuL6Jqu55IkzZDjfh1FkjuB9wPnJDlA566gG4G7k2wAngc+2rp/G7gMGAV+CVwLUFWHk3wWeKT1+0xVjb8p/bd07lh6M/Dv7SFJmkHHDYOqunqSptUT9C1g0yTPsw3YNkF9BHjv8cYhSTpx/ASyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJos8wSPLJJE8meSLJnUnOTLIsyZ4ko0m+meT01veMtj/a2oe7nuf6Vn86ySX9TUmSNFU9h0GSxcDHgZVV9V7gNOAq4Cbg5qp6J3AE2NAO2QAcafWbWz+SrGjHvQdYC3wpyWm9jkuSNHX9XiaaB7w5yTzgLcALwAeAHa19O3BF217X9mntq5Ok1e+qql9X1bPAKHBBn+OSJE1Bz2FQVQeBzwM/oRMCrwCPAi9X1dHW7QCwuG0vBva3Y4+2/m/vrk9wzGsk2ZhkJMnI2NhYr0OXJB2jn8tEC+j8Vb8MeAdwFp3LPCdMVW2tqpVVtXJoaOhEvpQkzSn9XCb6IPBsVY1V1W+Ae4CLgfntshHAEuBg2z4ILAVo7WcDP+uuT3CMJGkG9BMGPwFWJXlLu/a/GngKeAi4svVZD9zbtne2fVr7g1VVrX5Vu9toGbAc+F4f45IkTdG843eZWFXtSbID+D5wFHgM2ArcD9yV5HOtdns75Hbg60lGgcN07iCiqp5McjedIDkKbKqq3/Y6LknS1PUcBgBVtQXYckz5GSa4G6iqfgV8ZJLnuQG4oZ+xSJJ65yeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEn2GQZL5SXYk+VGSvUkuSrIwya4k+9rPBa1vktyaZDTJ40nO73qe9a3/viTr+52UJGlq+j0zuAX4TlW9G3gfsBfYDOyuquXA7rYPcCmwvD02ArcBJFkIbAEuBC4AtowHiCRpZvQcBknOBv4CuB2gqv6vql4G1gHbW7ftwBVtex1wR3U8DMxPci5wCbCrqg5X1RFgF7C213FJkqaunzODZcAY8NUkjyX5SpKzgEVV9ULr8yKwqG0vBvZ3HX+g1Sar/4EkG5OMJBkZGxvrY+iSpG79hME84Hzgtqo6D/gFv78kBEBVFVB9vMZrVNXWqlpZVSuHhoam62klac7rJwwOAAeqak/b30EnHF5ql39oPw+19oPA0q7jl7TaZHVJ0gzpOQyq6kVgf5J3tdJq4ClgJzB+R9B64N62vRO4pt1VtAp4pV1OegBYk2RBe+N4TatJkmbIvD6P/3vgG0lOB54BrqUTMHcn2QA8D3y09f02cBkwCvyy9aWqDif5LPBI6/eZqjrc57gkSVPQVxhU1Q+AlRM0rZ6gbwGbJnmebcC2fsYiSeqdn0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJTEMYJDktyWNJ7mv7y5LsSTKa5JtJTm/1M9r+aGsf7nqO61v96SSX9DsmSdLUTMeZwXXA3q79m4Cbq+qdwBFgQ6tvAI60+s2tH0lWAFcB7wHWAl9Kcto0jEuS9Ab1FQZJlgCXA19p+wE+AOxoXbYDV7TtdW2f1r669V8H3FVVv66qZ4FR4IJ+xiVJmpp+zwy+CHwa+F3bfzvwclUdbfsHgMVtezGwH6C1v9L6v1qf4JjXSLIxyUiSkbGxsT6HLkka13MYJPkQcKiqHp3G8byuqtpaVSurauXQ0NBMvawkzXrz+jj2YuDDSS4DzgTeBtwCzE8yr/31vwQ42PofBJYCB5LMA84GftZVH9d9jCRpBvR8ZlBV11fVkqoapvMG8INV9THgIeDK1m09cG/b3tn2ae0PVlW1+lXtbqNlwHLge72OS5I0df2cGUzmH4C7knwOeAy4vdVvB76eZBQ4TCdAqKonk9wNPAUcBTZV1W9PwLgkSZOYljCoqu8C323bzzDB3UBV9SvgI5McfwNww3SMRZI0dX4CWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNFHGCRZmuShJE8leTLJda2+MMmuJPvazwWtniS3JhlN8niS87uea33rvy/J+v6nJUmain7ODI4Cn6qqFcAqYFOSFcBmYHdVLQd2t32AS4Hl7bERuA064QFsAS4ELgC2jAeIJGlm9BwGVfVCVX2/bf8PsBdYDKwDtrdu24Er2vY64I7qeBiYn+Rc4BJgV1UdrqojwC5gba/jkiRN3bS8Z5BkGDgP2AMsqqoXWtOLwKK2vRjY33XYgVabrD7R62xMMpJkZGxsbDqGLkliGsIgyVuBbwGfqKqfd7dVVQHV72t0Pd/WqlpZVSuHhoam62klac7rKwySvIlOEHyjqu5p5Zfa5R/az0OtfhBY2nX4klabrC5JmiH93E0U4HZgb1V9oatpJzB+R9B64N6u+jXtrqJVwCvtctIDwJokC9obx2taTZI0Q+b1cezFwF8BP0zyg1b7R+BG4O4kG4DngY+2tm8DlwGjwC+BawGq6nCSzwKPtH6fqarDfYxLkjRFPYdBVf0XkEmaV0/Qv4BNkzzXNmBbr2ORJPXHTyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIn+vo5CUzS8+f6BvfZzN14+sNeWdPLzzECSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAmYN+gBaGYMb75/IK/73I2XD+R1JU3NSXNmkGRtkqeTjCbZPOjxSNJcclKEQZLTgH8BLgVWAFcnWTHYUUnS3HGyXCa6ABitqmcAktwFrAOeGuio1LdBXZ6aiwZ5Sc7LkKe+kyUMFgP7u/YPABce2ynJRmBj2/3fJE9P4TXOAX7a8whPXXNx3nNyzrlpzs2Z3DQ315re5/zHkzWcLGHwhlTVVmBrL8cmGamqldM8pJPeXJy3c5475uK8T9ScT4r3DICDwNKu/SWtJkmaASdLGDwCLE+yLMnpwFXAzgGPSZLmjJPiMlFVHU3yd8ADwGnAtqp6cppfpqfLS7PAXJy3c5475uK8T8icU1Un4nklSaeQk+UykSRpgAwDSdLcCIPZ+lUXSZYmeSjJU0meTHJdqy9MsivJvvZzQasnya3t9/B4kvMHO4PeJTktyWNJ7mv7y5LsaXP7ZrsRgSRntP3R1j48yHH3I8n8JDuS/CjJ3iQXzfa1TvLJ9m/7iSR3JjlzNq51km1JDiV5oqs25bVNsr7135dk/VTGMOvDYJZ/1cVR4FNVtQJYBWxqc9sM7K6q5cDutg+d38Hy9tgI3DbzQ5421wF7u/ZvAm6uqncCR4ANrb4BONLqN7d+p6pbgO9U1buB99GZ/6xd6ySLgY8DK6vqvXRuLrmK2bnWXwPWHlOb0tomWQhsofOB3QuALeMB8oZU1ax+ABcBD3TtXw9cP+hxnaC53gv8JfA0cG6rnQs83ba/DFzd1f/VfqfSg87nUHYDHwDuA0LnE5nzjl1zOneoXdS257V+GfQcepjz2cCzx459Nq81v/9mgoVt7e4DLpmtaw0MA0/0urbA1cCXu+qv6Xe8x6w/M2Dir7pYPKCxnDDtlPg8YA+wqKpeaE0vAova9mz5XXwR+DTwu7b/duDlqjra9rvn9eqcW/srrf+pZhkwBny1XR77SpKzmMVrXVUHgc8DPwFeoLN2jzL713rcVNe2rzWfC2Ew6yV5K/At4BNV9fPutur8iTBr7h9O8iHgUFU9OuixzLB5wPnAbVV1HvALfn/ZAJiVa72AzhdWLgPeAZzFH15KmRNmYm3nQhjM6q+6SPImOkHwjaq6p5VfSnJuaz8XONTqs+F3cTHw4STPAXfRuVR0CzA/yfiHKLvn9eqcW/vZwM9mcsDT5ABwoKr2tP0ddMJhNq/1B4Fnq2qsqn4D3ENn/Wf7Wo+b6tr2teZzIQxm7VddJAlwO7C3qr7Q1bQTGL+TYD2d9xLG69e0uxFWAa90nYaeEqrq+qpaUlXDdNbywar6GPAQcGXrduycx38XV7b+p9xfz1X1IrA/ybtaaTWdr3iftWtN5/LQqiRvaf/Wx+c8q9e6y1TX9gFgTZIF7axqTau9MYN+02SG3pi5DPhv4MfAPw16PNM4rz+nc+r4OPCD9riMznXS3cA+4D+Aha1/6NxZ9WPgh3Tu0hj4PPqY//uB+9r2nwDfA0aBfwXOaPUz2/5oa/+TQY+7j/n+KTDS1vvfgAWzfa2BfwZ+BDwBfB04YzauNXAnnfdFfkPnLHBDL2sL/HWb/yhw7VTG4NdRSJLmxGUiSdJxGAaSJMNAkmQYSJIwDCRJGAaSJAwDSRLw/7tjJQL96/aFAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nEFMUojsWaXo","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1592830420131,"user_tz":-120,"elapsed":895,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"d642ddc1-8b9b-4cd0-9d6a-26d137683e86"},"source":["# Etiqueta de la variable objetivo para el problema de clasificación\n","y = df_airbnb_images['Price']\n","y_class = []\n","\n","for x in y:\n","    # La variable objetivo se asocia a 5 clases barato, medio, medio alto, caro y  muy caro\n","    if x <= 50:\n","        y_class.append(0)\n","    elif x <=100:\n","        y_class.append(1)\n","    elif x <=150:\n","        y_class.append(2)\n","    elif x <=200:\n","        y_class.append(3)\n","    else:\n","        y_class.append(4)\n","\n","# y un rango para clasificación (del 1 al 5 por ejemplo: barato, medio, medio alto, caro y muy caro)\n","import matplotlib.pyplot as plt\n","plt.hist(y_class, bins=5)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"NhteTRn7UpJB","colab_type":"text"},"source":["#### **Regresión con imágenes**"]},{"cell_type":"code","metadata":{"id":"C1A3HLhSNI6B","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","\n","# Normalización de las imágenes\n","scaler = preprocessing.MinMaxScaler()\n","images_norm = scaler.fit_transform(images_fe)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-CdHnYtUa8R","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","# Normalización de las etiquetas\n","y_norm = y/y.max()\n","\n","# Vamos a dividir en train, validation y en test pero con una muestra de 2000 registros.\n","# La razón por la que hago esto es porque en el proceso de entrenamiento nuestro modelo se satura y el resultado final aún modificando\n","# los hiperparámetros o modificando las unidades de las capas densas siempre era el mismo loss: nan - val_loss: nan\n","X_train, X_test, y_train, y_test = train_test_split(images_norm[0:2000], y_norm[0:2000], test_size=0.33,  shuffle=True, random_state=0)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2,  shuffle=True, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKv7q7H-iCUH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1592826306132,"user_tz":-120,"elapsed":8609,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"3999bb07-9631-4519-8a59-be13294994ae"},"source":["from keras.optimizers import Adam\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.regularizers import l1, l1_l2\n","\n","# Creación del modelo MLP para el problema de regresión con imágenes la función de activación es 'linear' (sin función de activación)\n","model = Sequential()\n","model.add(Dense(16, input_shape=(X_train.shape[1],), activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","\n","# Optimizador Adam\n","opt = Adam(lr=0.001, decay=1e-6)\n","model.compile(loss=\"mean_squared_error\", optimizer=opt)\n","\n","# train the model\n","print(\"[INFO] training model...\")\n","history = model.fit(x=X_train, y=y_train, \n","\t        validation_data=(X_val, y_val),\n","\t        epochs=10, batch_size=16)  \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] training model...\n","Train on 1072 samples, validate on 268 samples\n","Epoch 1/10\n","1072/1072 [==============================] - 2s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n","Epoch 2/10\n","1072/1072 [==============================] - 0s 267us/step - loss: 0.0053 - val_loss: 0.0057\n","Epoch 3/10\n","1072/1072 [==============================] - 0s 259us/step - loss: 0.0047 - val_loss: 0.0055\n","Epoch 4/10\n","1072/1072 [==============================] - 0s 255us/step - loss: 0.0042 - val_loss: 0.0054\n","Epoch 5/10\n","1072/1072 [==============================] - 0s 249us/step - loss: 0.0038 - val_loss: 0.0053\n","Epoch 6/10\n","1072/1072 [==============================] - 0s 257us/step - loss: 0.0036 - val_loss: 0.0053\n","Epoch 7/10\n","1072/1072 [==============================] - 0s 257us/step - loss: 0.0032 - val_loss: 0.0053\n","Epoch 8/10\n","1072/1072 [==============================] - 0s 262us/step - loss: 0.0030 - val_loss: 0.0051\n","Epoch 9/10\n","1072/1072 [==============================] - 0s 249us/step - loss: 0.0027 - val_loss: 0.0053\n","Epoch 10/10\n","1072/1072 [==============================] - 0s 263us/step - loss: 0.0026 - val_loss: 0.0052\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mxaK_Ghu0MeN","colab_type":"text"},"source":["\n","\n","``` \n","Epoch 10/10  \n","1072/1072 [=============] - 0s 137us/step - loss: 0.0021 - val_loss: 0.0065 opt = Adam(lr=0.001, decay=1e-6)  batch_size=32 Dense 32\n","1072/1072 [=============] - 0s 128us/step - loss: 0.0034 - val_loss: 0.0051 opt = Adam(lr=0.001, decay=1e-6)  batch_size=32 Dense 8\n","1072/1072 [=============] - 0s 137us/step - loss: 7.6088e-04 - val_loss: 0.0055 opt = Adam(lr=0.001, decay=1e-6)  batch_size=32 Dense 64 y 32\n","1072/1072 [=============] - 0s 134us/step - loss: 0.0036 - val_loss: 0.0056 opt = Adam(lr=0.001, decay=1e-6)  batch_size=32 Dense 16\n","1072/1072 [=============] - 0s 263us/step - loss: 0.0026 - val_loss: 0.0052 opt = Adam(lr=0.001, decay=1e-6)  batch_size=16 Dense 16\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O8kzrevv2axf","colab_type":"text"},"source":["Para la muestra completa de las imágenes descargadas, el resultado en el entrenamiento siempre ha sido el mismo **loss: nan - val_loss: nan**, aún modificando los valores de los hiperparámetros (learning rate, batch size, epochs), parametros en el optimizador Adam utilizado,  aplicando Dropout y regularización l1 o mixta l1_l2, además de variar las unidades de la capa densa del modelo MLP.\n","\n","Ahora, con la muestra de 2000 imágenes, si se han conseguido estos resultados.\n","\n","Nos quedamos con el modelo con una capa densa de 16 units y un batch size de 16 ya que obtenemos el mínimo valor en la función de perdidas conjuntamente en train y validation"]},{"cell_type":"code","metadata":{"id":"4UWlBnc92Xia","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592827624357,"user_tz":-120,"elapsed":19698,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"5fa7d21e-b0af-4a50-b86e-a72c066c5871"},"source":["from keras.optimizers import Adam\n","from keras.models import Sequential\n","\n","# Creación del modelo MLP para el problema de regresión con imágenes la función de activación es 'linear' (sin función de activación)\n","model = Sequential()\n","model.add(Dense(16, input_shape=(X_train.shape[1],), activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","\n","# Optimizador Adam\n","opt = Adam(lr=0.001, decay=1e-6)\n","model.compile(loss=\"mean_squared_error\", optimizer=opt)\n","\n","# train the model\n","print(\"[INFO] training model...\")\n","history = model.fit(x=X_train, y=y_train, \n","\t        validation_data=(X_val, y_val),\n","\t        epochs=50, batch_size=16)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] training model...\n","Train on 1072 samples, validate on 268 samples\n","Epoch 1/50\n","1072/1072 [==============================] - 2s 2ms/step - loss: 0.0081 - val_loss: 0.0058\n","Epoch 2/50\n","1072/1072 [==============================] - 0s 261us/step - loss: 0.0050 - val_loss: 0.0055\n","Epoch 3/50\n","1072/1072 [==============================] - 0s 254us/step - loss: 0.0044 - val_loss: 0.0051\n","Epoch 4/50\n","1072/1072 [==============================] - 0s 257us/step - loss: 0.0039 - val_loss: 0.0056\n","Epoch 5/50\n","1072/1072 [==============================] - 0s 257us/step - loss: 0.0035 - val_loss: 0.0051\n","Epoch 6/50\n","1072/1072 [==============================] - 0s 262us/step - loss: 0.0031 - val_loss: 0.0051\n","Epoch 7/50\n","1072/1072 [==============================] - 0s 277us/step - loss: 0.0028 - val_loss: 0.0050\n","Epoch 8/50\n","1072/1072 [==============================] - 0s 247us/step - loss: 0.0024 - val_loss: 0.0051\n","Epoch 9/50\n","1072/1072 [==============================] - 0s 266us/step - loss: 0.0021 - val_loss: 0.0051\n","Epoch 10/50\n","1072/1072 [==============================] - 0s 255us/step - loss: 0.0019 - val_loss: 0.0052\n","Epoch 11/50\n","1072/1072 [==============================] - 0s 252us/step - loss: 0.0018 - val_loss: 0.0053\n","Epoch 12/50\n","1072/1072 [==============================] - 0s 257us/step - loss: 0.0015 - val_loss: 0.0052\n","Epoch 13/50\n","1072/1072 [==============================] - 0s 251us/step - loss: 0.0014 - val_loss: 0.0050\n","Epoch 14/50\n","1072/1072 [==============================] - 0s 256us/step - loss: 0.0012 - val_loss: 0.0053\n","Epoch 15/50\n","1072/1072 [==============================] - 0s 253us/step - loss: 0.0011 - val_loss: 0.0052\n","Epoch 16/50\n","1072/1072 [==============================] - 0s 261us/step - loss: 9.6879e-04 - val_loss: 0.0053\n","Epoch 17/50\n","1072/1072 [==============================] - 0s 251us/step - loss: 8.4612e-04 - val_loss: 0.0053\n","Epoch 18/50\n","1072/1072 [==============================] - 0s 255us/step - loss: 7.8785e-04 - val_loss: 0.0054\n","Epoch 19/50\n","1072/1072 [==============================] - 0s 250us/step - loss: 6.9474e-04 - val_loss: 0.0054\n","Epoch 20/50\n","1072/1072 [==============================] - 0s 262us/step - loss: 5.8317e-04 - val_loss: 0.0053\n","Epoch 21/50\n","1072/1072 [==============================] - 0s 256us/step - loss: 5.3650e-04 - val_loss: 0.0054\n","Epoch 22/50\n","1072/1072 [==============================] - 0s 253us/step - loss: 4.8562e-04 - val_loss: 0.0055\n","Epoch 23/50\n","1072/1072 [==============================] - 0s 247us/step - loss: 4.3468e-04 - val_loss: 0.0053\n","Epoch 24/50\n","1072/1072 [==============================] - 0s 262us/step - loss: 4.0400e-04 - val_loss: 0.0055\n","Epoch 25/50\n","1072/1072 [==============================] - 0s 249us/step - loss: 3.7024e-04 - val_loss: 0.0055\n","Epoch 26/50\n","1072/1072 [==============================] - 0s 249us/step - loss: 3.4327e-04 - val_loss: 0.0057\n","Epoch 27/50\n","1072/1072 [==============================] - 0s 258us/step - loss: 3.0014e-04 - val_loss: 0.0055\n","Epoch 28/50\n","1072/1072 [==============================] - 0s 246us/step - loss: 2.8186e-04 - val_loss: 0.0058\n","Epoch 29/50\n","1072/1072 [==============================] - 0s 256us/step - loss: 2.8028e-04 - val_loss: 0.0056\n","Epoch 30/50\n","1072/1072 [==============================] - 0s 257us/step - loss: 2.7214e-04 - val_loss: 0.0056\n","Epoch 31/50\n","1072/1072 [==============================] - 0s 259us/step - loss: 2.4808e-04 - val_loss: 0.0057\n","Epoch 32/50\n","1072/1072 [==============================] - 0s 250us/step - loss: 2.3290e-04 - val_loss: 0.0055\n","Epoch 33/50\n","1072/1072 [==============================] - 0s 253us/step - loss: 2.2177e-04 - val_loss: 0.0057\n","Epoch 34/50\n","1072/1072 [==============================] - 0s 252us/step - loss: 2.2047e-04 - val_loss: 0.0055\n","Epoch 35/50\n","1072/1072 [==============================] - 0s 260us/step - loss: 2.2742e-04 - val_loss: 0.0056\n","Epoch 36/50\n","1072/1072 [==============================] - 0s 262us/step - loss: 2.2131e-04 - val_loss: 0.0055\n","Epoch 37/50\n","1072/1072 [==============================] - 0s 250us/step - loss: 2.2500e-04 - val_loss: 0.0057\n","Epoch 38/50\n","1072/1072 [==============================] - 0s 248us/step - loss: 2.4121e-04 - val_loss: 0.0057\n","Epoch 39/50\n","1072/1072 [==============================] - 0s 257us/step - loss: 2.7766e-04 - val_loss: 0.0056\n","Epoch 40/50\n","1072/1072 [==============================] - 0s 253us/step - loss: 3.1638e-04 - val_loss: 0.0055\n","Epoch 41/50\n","1072/1072 [==============================] - 0s 251us/step - loss: 2.9263e-04 - val_loss: 0.0058\n","Epoch 42/50\n","1072/1072 [==============================] - 0s 270us/step - loss: 2.9528e-04 - val_loss: 0.0057\n","Epoch 43/50\n","1072/1072 [==============================] - 0s 249us/step - loss: 2.6628e-04 - val_loss: 0.0056\n","Epoch 44/50\n","1072/1072 [==============================] - 0s 264us/step - loss: 2.2064e-04 - val_loss: 0.0056\n","Epoch 45/50\n","1072/1072 [==============================] - 0s 263us/step - loss: 2.0051e-04 - val_loss: 0.0055\n","Epoch 46/50\n","1072/1072 [==============================] - 0s 255us/step - loss: 1.8766e-04 - val_loss: 0.0057\n","Epoch 47/50\n","1072/1072 [==============================] - 0s 255us/step - loss: 1.7891e-04 - val_loss: 0.0056\n","Epoch 48/50\n","1072/1072 [==============================] - 0s 252us/step - loss: 1.7824e-04 - val_loss: 0.0057\n","Epoch 49/50\n","1072/1072 [==============================] - 0s 245us/step - loss: 1.8571e-04 - val_loss: 0.0056\n","Epoch 50/50\n","1072/1072 [==============================] - 0s 258us/step - loss: 1.9605e-04 - val_loss: 0.0056\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BWDcgUAq7NJz","colab_type":"text"},"source":["\n","\n","```\n","Epoch 50/50\n","1072/1072 [==============================] - 0s 258us/step - loss: 1.9605e-04 - val_loss: 0.0056 \n","```\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EC-5tgSnS4IQ","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592827656449,"user_tz":-120,"elapsed":595,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"d5733a55-bff1-439c-c654-c46818addd00"},"source":["# Evaluamos la función de perdidas en test\n","loss = model.evaluate(X_test, y_test)\n","print(f'Loss={loss}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["660/660 [==============================] - 0s 87us/step\n","Loss=0.005767127233698512\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qr6k8omzS4IV","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1592827742164,"user_tz":-120,"elapsed":643,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"48b2f404-c8a5-4dfa-acbb-b2cc2b5ce5b7"},"source":["import locale\n","\n","# make predictions on the testing data\n","print(\"[INFO] predicting house prices airbnb ...\")\n","preds = model.predict(X_test)\n","\n","# compute the difference between the *predicted* house prices and the\n","# *actual* house prices, then compute the percentage difference and\n","# the absolute percentage difference\n","diff = preds.flatten() - y_test\n","percentDiff = (diff / y_test) * 100\n","absPercentDiff = np.abs(percentDiff)\n","\n","# compute the mean and standard deviation of the absolute percentage\n","# difference\n","mean = np.mean(absPercentDiff)\n","std = np.std(absPercentDiff)\n","\n","# finally, show some statistics on our model\n","locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n","print(\"[INFO] avg. house price: {}, std house price: {}\".format(\n","\tlocale.currency(y.mean(), grouping=True),\n","\tlocale.currency(y.std(), grouping=True)))\n","print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] predicting house prices airbnb ...\n","[INFO] avg. house price: $68.26, std house price: $68.01\n","[INFO] mean: 84.70%, std: 101.76%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c5ysRLD-7dqi","colab_type":"text"},"source":["Nuestro mean_squared_error final implica que, en promedio, nuestra red tendrá un ~ 85% de descuento en sus predicciones del precio de la vivienda con una desviación estándar de ~ 101.7%. \n","\n","```\n","[INFO] predicting house prices airbnb ...\n","[INFO] avg. house price: $68.26, std house price: $68.01\n","[INFO] mean: 84.70%, std: 101.76%\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xFjIix_nUxw6","colab_type":"text"},"source":["#### **Clasificación con imágenes**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HHoUxB8SchB2","colab":{}},"source":["from sklearn import preprocessing\n","\n","# Normalización de las imágenes\n","scaler = preprocessing.MinMaxScaler()\n","images_norm = scaler.fit_transform(images_fe)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uYgU37D9chCD","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","\n","# Clasificación de la etiqueta objetivo Price en 5 clases \n","y_norm = to_categorical(y_class)\n","\n","# Vamos a dividir en train, validation y en test con la muestra completa de las imágenes\n","X_train, X_test, y_train, y_test = train_test_split(images_norm, y_norm, test_size=0.33,  shuffle=True, random_state=0)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2,  shuffle=True, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SqZRbQfcipl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592828807825,"user_tz":-120,"elapsed":54614,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"9fc338c8-1749-4d74-d183-e53c6d1f37e9"},"source":["# Modelo para el problema de clasificación (función de perdida categorical_crossentropy y metrica accuracy y función de activación softmax)\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","model = Sequential()\n","model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(5, activation='softmax'))\n","\n","# sparse_categorical_crossentropy es exactamente igual que categorical_crossentropy,\n","# solo que admite enteros en vez de onehot a la entrada\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_val, y_val),\n","          epochs=50,\n","          batch_size=32)\n","\n","loss, acc = model.evaluate(X_val, y_val)\n","print(f'Loss={loss}, Acc={acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 6400 samples, validate on 1601 samples\n","Epoch 1/50\n","6400/6400 [==============================] - 2s 348us/step - loss: 1.1108 - accuracy: 0.5255 - val_loss: 1.0119 - val_accuracy: 0.6046\n","Epoch 2/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.9947 - accuracy: 0.5966 - val_loss: 0.9872 - val_accuracy: 0.6184\n","Epoch 3/50\n","6400/6400 [==============================] - 1s 149us/step - loss: 0.9649 - accuracy: 0.6080 - val_loss: 0.9822 - val_accuracy: 0.6146\n","Epoch 4/50\n","6400/6400 [==============================] - 1s 144us/step - loss: 0.9430 - accuracy: 0.6162 - val_loss: 0.9983 - val_accuracy: 0.6184\n","Epoch 5/50\n","6400/6400 [==============================] - 1s 149us/step - loss: 0.9233 - accuracy: 0.6291 - val_loss: 0.9895 - val_accuracy: 0.6096\n","Epoch 6/50\n","6400/6400 [==============================] - 1s 154us/step - loss: 0.9021 - accuracy: 0.6391 - val_loss: 0.9985 - val_accuracy: 0.6159\n","Epoch 7/50\n","6400/6400 [==============================] - 1s 154us/step - loss: 0.8836 - accuracy: 0.6420 - val_loss: 1.0258 - val_accuracy: 0.5978\n","Epoch 8/50\n","6400/6400 [==============================] - 1s 152us/step - loss: 0.8579 - accuracy: 0.6533 - val_loss: 1.0253 - val_accuracy: 0.6109\n","Epoch 9/50\n","6400/6400 [==============================] - 1s 153us/step - loss: 0.8372 - accuracy: 0.6620 - val_loss: 1.0352 - val_accuracy: 0.6021\n","Epoch 10/50\n","6400/6400 [==============================] - 1s 152us/step - loss: 0.8003 - accuracy: 0.6783 - val_loss: 1.0517 - val_accuracy: 0.5978\n","Epoch 11/50\n","6400/6400 [==============================] - 1s 150us/step - loss: 0.7739 - accuracy: 0.6911 - val_loss: 1.0771 - val_accuracy: 0.5940\n","Epoch 12/50\n","6400/6400 [==============================] - 1s 144us/step - loss: 0.7324 - accuracy: 0.7066 - val_loss: 1.0971 - val_accuracy: 0.5965\n","Epoch 13/50\n","6400/6400 [==============================] - 1s 150us/step - loss: 0.7046 - accuracy: 0.7261 - val_loss: 1.1135 - val_accuracy: 0.5946\n","Epoch 14/50\n","6400/6400 [==============================] - 1s 150us/step - loss: 0.6679 - accuracy: 0.7383 - val_loss: 1.1757 - val_accuracy: 0.5659\n","Epoch 15/50\n","6400/6400 [==============================] - 1s 149us/step - loss: 0.6200 - accuracy: 0.7663 - val_loss: 1.2031 - val_accuracy: 0.5790\n","Epoch 16/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.5862 - accuracy: 0.7744 - val_loss: 1.2543 - val_accuracy: 0.5778\n","Epoch 17/50\n","6400/6400 [==============================] - 1s 149us/step - loss: 0.5431 - accuracy: 0.7980 - val_loss: 1.3034 - val_accuracy: 0.5621\n","Epoch 18/50\n","6400/6400 [==============================] - 1s 145us/step - loss: 0.4954 - accuracy: 0.8177 - val_loss: 1.3496 - val_accuracy: 0.5490\n","Epoch 19/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.4694 - accuracy: 0.8289 - val_loss: 1.4374 - val_accuracy: 0.5621\n","Epoch 20/50\n","6400/6400 [==============================] - 1s 152us/step - loss: 0.4303 - accuracy: 0.8456 - val_loss: 1.4620 - val_accuracy: 0.5740\n","Epoch 21/50\n","6400/6400 [==============================] - 1s 149us/step - loss: 0.3929 - accuracy: 0.8612 - val_loss: 1.5495 - val_accuracy: 0.5609\n","Epoch 22/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.3674 - accuracy: 0.8720 - val_loss: 1.6218 - val_accuracy: 0.5459\n","Epoch 23/50\n","6400/6400 [==============================] - 1s 149us/step - loss: 0.3282 - accuracy: 0.8886 - val_loss: 1.7240 - val_accuracy: 0.5690\n","Epoch 24/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.2888 - accuracy: 0.9072 - val_loss: 1.7627 - val_accuracy: 0.5565\n","Epoch 25/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.2704 - accuracy: 0.9136 - val_loss: 1.8490 - val_accuracy: 0.5603\n","Epoch 26/50\n","6400/6400 [==============================] - 1s 151us/step - loss: 0.2384 - accuracy: 0.9261 - val_loss: 1.9080 - val_accuracy: 0.5503\n","Epoch 27/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.2126 - accuracy: 0.9394 - val_loss: 2.0122 - val_accuracy: 0.5497\n","Epoch 28/50\n","6400/6400 [==============================] - 1s 149us/step - loss: 0.1921 - accuracy: 0.9484 - val_loss: 2.1748 - val_accuracy: 0.5472\n","Epoch 29/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.1716 - accuracy: 0.9583 - val_loss: 2.1554 - val_accuracy: 0.5303\n","Epoch 30/50\n","6400/6400 [==============================] - 1s 145us/step - loss: 0.1512 - accuracy: 0.9636 - val_loss: 2.2561 - val_accuracy: 0.5459\n","Epoch 31/50\n","6400/6400 [==============================] - 1s 150us/step - loss: 0.1472 - accuracy: 0.9627 - val_loss: 2.3511 - val_accuracy: 0.5515\n","Epoch 32/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.1254 - accuracy: 0.9723 - val_loss: 2.4532 - val_accuracy: 0.5340\n","Epoch 33/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.1134 - accuracy: 0.9750 - val_loss: 2.5964 - val_accuracy: 0.5228\n","Epoch 34/50\n","6400/6400 [==============================] - 1s 150us/step - loss: 0.0904 - accuracy: 0.9839 - val_loss: 2.6663 - val_accuracy: 0.5365\n","Epoch 35/50\n","6400/6400 [==============================] - 1s 151us/step - loss: 0.0930 - accuracy: 0.9816 - val_loss: 2.7803 - val_accuracy: 0.5234\n","Epoch 36/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.0790 - accuracy: 0.9867 - val_loss: 2.8297 - val_accuracy: 0.5422\n","Epoch 37/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0722 - accuracy: 0.9891 - val_loss: 2.8364 - val_accuracy: 0.5247\n","Epoch 38/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.0691 - accuracy: 0.9870 - val_loss: 2.9738 - val_accuracy: 0.5359\n","Epoch 39/50\n","6400/6400 [==============================] - 1s 146us/step - loss: 0.0704 - accuracy: 0.9861 - val_loss: 3.0920 - val_accuracy: 0.5278\n","Epoch 40/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.0619 - accuracy: 0.9898 - val_loss: 3.1231 - val_accuracy: 0.5372\n","Epoch 41/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0695 - accuracy: 0.9862 - val_loss: 3.1762 - val_accuracy: 0.5415\n","Epoch 42/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.0582 - accuracy: 0.9898 - val_loss: 3.2916 - val_accuracy: 0.5184\n","Epoch 43/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0611 - accuracy: 0.9897 - val_loss: 3.3230 - val_accuracy: 0.5334\n","Epoch 44/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0540 - accuracy: 0.9911 - val_loss: 3.3945 - val_accuracy: 0.5141\n","Epoch 45/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.0539 - accuracy: 0.9908 - val_loss: 3.4069 - val_accuracy: 0.5309\n","Epoch 46/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0512 - accuracy: 0.9902 - val_loss: 3.5185 - val_accuracy: 0.5159\n","Epoch 47/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0457 - accuracy: 0.9925 - val_loss: 3.5583 - val_accuracy: 0.5197\n","Epoch 48/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0865 - accuracy: 0.9759 - val_loss: 3.6306 - val_accuracy: 0.5378\n","Epoch 49/50\n","6400/6400 [==============================] - 1s 148us/step - loss: 0.0627 - accuracy: 0.9839 - val_loss: 3.5014 - val_accuracy: 0.4884\n","Epoch 50/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.0492 - accuracy: 0.9911 - val_loss: 3.5713 - val_accuracy: 0.5547\n","1601/1601 [==============================] - 0s 91us/step\n","Loss=3.571327621083495, Acc=0.5546533465385437\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XgwHlz0Yfeyw","colab_type":"text"},"source":["Accuracy obtenido en train es aproximadamente de un 99% y un 55% en validación, existe overfitting.\n","\n","```\n","Epoch 50/50\n","6400/6400 [==============================] - 1s 147us/step - loss: 0.0492 - accuracy: 0.9911 - val_loss: 3.5713 - val_accuracy: 0.5547\n","1601/1601 [==============================] - 0s 91us/step\n","Loss=3.571327621083495, Acc=0.5546533465385437\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LqwABawCfpNh","colab_type":"text"},"source":["\n","\n","Vamos a realizar las siguientes pruebas:\n","\n","- The Dropout layer randomly sets input units to 0 which helps prevent overfitting con L1\n","- Dropout con L1+L2\n","- BatchNormalization y MaxPooling en redes convolucionales\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"brvvLQnlhPth","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592828922178,"user_tz":-120,"elapsed":58462,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"e2e980c8-3b9a-4542-d057-b24956acd045"},"source":["# Etapa de clasificación (capas densas con L1 +dropout+softmax con Adam como optimizador)\n","# Modelo para el problema de clasificación (función de perdida categorical_crossentropy y metrica accuracy)\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.regularizers import l1\n","from keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l1(0.01)))\n","model.add(Dropout(0.2))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(5, activation='softmax'))\n","\n","# sparse_categorical_crossentropy es exactamente igual que categorical_crossentropy,\n","# solo que admite enteros en vez de onehot a la entrada\n","opt = Adam(lr=1e-4, decay=1e-4)\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_val, y_val),\n","          epochs=50,\n","          batch_size=32)\n","\n","loss, acc = model.evaluate(X_val, y_val)\n","print(f'Loss={loss}, Acc={acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 6400 samples, validate on 1601 samples\n","Epoch 1/50\n","6400/6400 [==============================] - 2s 368us/step - loss: 15.1772 - accuracy: 0.3847 - val_loss: 12.3139 - val_accuracy: 0.5166\n","Epoch 2/50\n","6400/6400 [==============================] - 1s 157us/step - loss: 9.9267 - accuracy: 0.4888 - val_loss: 7.7167 - val_accuracy: 0.5128\n","Epoch 3/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 6.0027 - accuracy: 0.4919 - val_loss: 4.4398 - val_accuracy: 0.5122\n","Epoch 4/50\n","6400/6400 [==============================] - 1s 156us/step - loss: 3.3311 - accuracy: 0.4966 - val_loss: 2.3517 - val_accuracy: 0.5122\n","Epoch 5/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.7890 - accuracy: 0.4969 - val_loss: 1.3469 - val_accuracy: 0.5122\n","Epoch 6/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.2547 - accuracy: 0.4986 - val_loss: 1.1890 - val_accuracy: 0.5122\n","Epoch 7/50\n","6400/6400 [==============================] - 1s 157us/step - loss: 1.1971 - accuracy: 0.4902 - val_loss: 1.1664 - val_accuracy: 0.5122\n","Epoch 8/50\n","6400/6400 [==============================] - 1s 156us/step - loss: 1.1810 - accuracy: 0.4948 - val_loss: 1.1538 - val_accuracy: 0.5122\n","Epoch 9/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1728 - accuracy: 0.4903 - val_loss: 1.1464 - val_accuracy: 0.5122\n","Epoch 10/50\n","6400/6400 [==============================] - 1s 156us/step - loss: 1.1686 - accuracy: 0.4934 - val_loss: 1.1416 - val_accuracy: 0.5122\n","Epoch 11/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1603 - accuracy: 0.4981 - val_loss: 1.1380 - val_accuracy: 0.5122\n","Epoch 12/50\n","6400/6400 [==============================] - 1s 157us/step - loss: 1.1512 - accuracy: 0.5030 - val_loss: 1.1344 - val_accuracy: 0.5122\n","Epoch 13/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1500 - accuracy: 0.4989 - val_loss: 1.1323 - val_accuracy: 0.5122\n","Epoch 14/50\n","6400/6400 [==============================] - 1s 159us/step - loss: 1.1493 - accuracy: 0.4953 - val_loss: 1.1308 - val_accuracy: 0.5122\n","Epoch 15/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1467 - accuracy: 0.4970 - val_loss: 1.1294 - val_accuracy: 0.5122\n","Epoch 16/50\n","6400/6400 [==============================] - 1s 155us/step - loss: 1.1461 - accuracy: 0.4964 - val_loss: 1.1281 - val_accuracy: 0.5122\n","Epoch 17/50\n","6400/6400 [==============================] - 1s 159us/step - loss: 1.1454 - accuracy: 0.4994 - val_loss: 1.1270 - val_accuracy: 0.5122\n","Epoch 18/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1451 - accuracy: 0.4995 - val_loss: 1.1265 - val_accuracy: 0.5122\n","Epoch 19/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1443 - accuracy: 0.4980 - val_loss: 1.1258 - val_accuracy: 0.5122\n","Epoch 20/50\n","6400/6400 [==============================] - 1s 157us/step - loss: 1.1406 - accuracy: 0.4992 - val_loss: 1.1253 - val_accuracy: 0.5122\n","Epoch 21/50\n","6400/6400 [==============================] - 1s 163us/step - loss: 1.1416 - accuracy: 0.4994 - val_loss: 1.1252 - val_accuracy: 0.5122\n","Epoch 22/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1404 - accuracy: 0.4925 - val_loss: 1.1248 - val_accuracy: 0.5122\n","Epoch 23/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1414 - accuracy: 0.4963 - val_loss: 1.1244 - val_accuracy: 0.5122\n","Epoch 24/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1369 - accuracy: 0.4998 - val_loss: 1.1239 - val_accuracy: 0.5122\n","Epoch 25/50\n","6400/6400 [==============================] - 1s 169us/step - loss: 1.1409 - accuracy: 0.5009 - val_loss: 1.1241 - val_accuracy: 0.5122\n","Epoch 26/50\n","6400/6400 [==============================] - 1s 166us/step - loss: 1.1365 - accuracy: 0.5033 - val_loss: 1.1239 - val_accuracy: 0.5122\n","Epoch 27/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1388 - accuracy: 0.5025 - val_loss: 1.1234 - val_accuracy: 0.5122\n","Epoch 28/50\n","6400/6400 [==============================] - 1s 163us/step - loss: 1.1371 - accuracy: 0.5031 - val_loss: 1.1233 - val_accuracy: 0.5122\n","Epoch 29/50\n","6400/6400 [==============================] - 1s 160us/step - loss: 1.1396 - accuracy: 0.4991 - val_loss: 1.1229 - val_accuracy: 0.5122\n","Epoch 30/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1364 - accuracy: 0.5022 - val_loss: 1.1232 - val_accuracy: 0.5122\n","Epoch 31/50\n","6400/6400 [==============================] - 1s 162us/step - loss: 1.1380 - accuracy: 0.5033 - val_loss: 1.1224 - val_accuracy: 0.5122\n","Epoch 32/50\n","6400/6400 [==============================] - 1s 163us/step - loss: 1.1378 - accuracy: 0.4992 - val_loss: 1.1228 - val_accuracy: 0.5122\n","Epoch 33/50\n","6400/6400 [==============================] - 1s 160us/step - loss: 1.1367 - accuracy: 0.5006 - val_loss: 1.1220 - val_accuracy: 0.5122\n","Epoch 34/50\n","6400/6400 [==============================] - 1s 159us/step - loss: 1.1396 - accuracy: 0.5030 - val_loss: 1.1221 - val_accuracy: 0.5122\n","Epoch 35/50\n","6400/6400 [==============================] - 1s 160us/step - loss: 1.1422 - accuracy: 0.4989 - val_loss: 1.1218 - val_accuracy: 0.5122\n","Epoch 36/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1370 - accuracy: 0.5033 - val_loss: 1.1217 - val_accuracy: 0.5122\n","Epoch 37/50\n","6400/6400 [==============================] - 1s 157us/step - loss: 1.1379 - accuracy: 0.4986 - val_loss: 1.1214 - val_accuracy: 0.5122\n","Epoch 38/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1361 - accuracy: 0.5047 - val_loss: 1.1210 - val_accuracy: 0.5122\n","Epoch 39/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1301 - accuracy: 0.5027 - val_loss: 1.1208 - val_accuracy: 0.5122\n","Epoch 40/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1320 - accuracy: 0.5028 - val_loss: 1.1202 - val_accuracy: 0.5122\n","Epoch 41/50\n","6400/6400 [==============================] - 1s 161us/step - loss: 1.1348 - accuracy: 0.5019 - val_loss: 1.1202 - val_accuracy: 0.5122\n","Epoch 42/50\n","6400/6400 [==============================] - 1s 160us/step - loss: 1.1348 - accuracy: 0.5005 - val_loss: 1.1199 - val_accuracy: 0.5122\n","Epoch 43/50\n","6400/6400 [==============================] - 1s 160us/step - loss: 1.1343 - accuracy: 0.5059 - val_loss: 1.1197 - val_accuracy: 0.5122\n","Epoch 44/50\n","6400/6400 [==============================] - 1s 162us/step - loss: 1.1376 - accuracy: 0.5009 - val_loss: 1.1195 - val_accuracy: 0.5122\n","Epoch 45/50\n","6400/6400 [==============================] - 1s 162us/step - loss: 1.1324 - accuracy: 0.5017 - val_loss: 1.1191 - val_accuracy: 0.5122\n","Epoch 46/50\n","6400/6400 [==============================] - 1s 159us/step - loss: 1.1325 - accuracy: 0.5055 - val_loss: 1.1188 - val_accuracy: 0.5122\n","Epoch 47/50\n","6400/6400 [==============================] - 1s 160us/step - loss: 1.1275 - accuracy: 0.5058 - val_loss: 1.1185 - val_accuracy: 0.5122\n","Epoch 48/50\n","6400/6400 [==============================] - 1s 160us/step - loss: 1.1326 - accuracy: 0.5013 - val_loss: 1.1181 - val_accuracy: 0.5122\n","Epoch 49/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1291 - accuracy: 0.5045 - val_loss: 1.1181 - val_accuracy: 0.5122\n","Epoch 50/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1295 - accuracy: 0.5028 - val_loss: 1.1177 - val_accuracy: 0.5122\n","1601/1601 [==============================] - 0s 92us/step\n","Loss=1.1176548570785427, Acc=0.5121799111366272\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p148aZyYj_QQ","colab_type":"text"},"source":["El accuracy obtenido en train 50.28% es incluso algo inferior al de validación 51.22%, observamos que el modelo no está aprendiendo con Dropout y regularización L1\n","\n","```\n","Epoch 50/50\n","6400/6400 [==============================] - 1s 158us/step - loss: 1.1295 - accuracy: 0.5028 - val_loss: 1.1177 - val_accuracy: 0.5122\n","1601/1601 [==============================] - 0s 92us/step\n","Loss=1.1176548570785427, Acc=0.5121799111366272\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"WpD5LZpNfmjw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592829027176,"user_tz":-120,"elapsed":21335,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"fed45663-42d1-42dc-fc64-86090f4da240"},"source":["# Etapa de clasificación (capas densas con L1_L2 +dropout+softmax)\n","# Modelo para el problema de clasificación (función de perdida categorical_crossentropy y metrica accuracy)\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.regularizers import l1_l2\n","from keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l1_l2(0.01)))\n","model.add(Dropout(0.2))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(5, activation='softmax'))\n","\n","# sparse_categorical_crossentropy es exactamente igual que categorical_crossentropy,\n","# solo que admite enteros en vez de onehot a la entrada\n","opt = Adam(lr=1e-3, decay=1e-4)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_val, y_val),\n","          epochs=50,\n","          batch_size=128)\n","\n","loss, acc = model.evaluate(X_val, y_val)\n","print(f'Loss={loss}, Acc={acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 6400 samples, validate on 1601 samples\n","Epoch 1/50\n","6400/6400 [==============================] - 2s 261us/step - loss: 11.9866 - accuracy: 0.4225 - val_loss: 5.9552 - val_accuracy: 0.5116\n","Epoch 2/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 3.0869 - accuracy: 0.4789 - val_loss: 1.3752 - val_accuracy: 0.5122\n","Epoch 3/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.2492 - accuracy: 0.4903 - val_loss: 1.1737 - val_accuracy: 0.5122\n","Epoch 4/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1871 - accuracy: 0.4917 - val_loss: 1.1663 - val_accuracy: 0.5122\n","Epoch 5/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1799 - accuracy: 0.4931 - val_loss: 1.1677 - val_accuracy: 0.5122\n","Epoch 6/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1805 - accuracy: 0.4991 - val_loss: 1.1635 - val_accuracy: 0.5122\n","Epoch 7/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1800 - accuracy: 0.4994 - val_loss: 1.1644 - val_accuracy: 0.5122\n","Epoch 8/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1814 - accuracy: 0.4977 - val_loss: 1.1640 - val_accuracy: 0.5122\n","Epoch 9/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1723 - accuracy: 0.5014 - val_loss: 1.1605 - val_accuracy: 0.5122\n","Epoch 10/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1699 - accuracy: 0.5011 - val_loss: 1.1574 - val_accuracy: 0.5122\n","Epoch 11/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1726 - accuracy: 0.5036 - val_loss: 1.1526 - val_accuracy: 0.5122\n","Epoch 12/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1678 - accuracy: 0.5072 - val_loss: 1.1467 - val_accuracy: 0.5122\n","Epoch 13/50\n","6400/6400 [==============================] - 0s 41us/step - loss: 1.1597 - accuracy: 0.5084 - val_loss: 1.1391 - val_accuracy: 0.5122\n","Epoch 14/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1588 - accuracy: 0.5163 - val_loss: 1.1274 - val_accuracy: 0.5459\n","Epoch 15/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1555 - accuracy: 0.5159 - val_loss: 1.1217 - val_accuracy: 0.5490\n","Epoch 16/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1554 - accuracy: 0.5231 - val_loss: 1.1236 - val_accuracy: 0.5646\n","Epoch 17/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1541 - accuracy: 0.5323 - val_loss: 1.1156 - val_accuracy: 0.5809\n","Epoch 18/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1496 - accuracy: 0.5269 - val_loss: 1.1154 - val_accuracy: 0.5959\n","Epoch 19/50\n","6400/6400 [==============================] - 0s 41us/step - loss: 1.1511 - accuracy: 0.5275 - val_loss: 1.1129 - val_accuracy: 0.5971\n","Epoch 20/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1489 - accuracy: 0.5361 - val_loss: 1.1132 - val_accuracy: 0.5990\n","Epoch 21/50\n","6400/6400 [==============================] - 0s 41us/step - loss: 1.1430 - accuracy: 0.5475 - val_loss: 1.1094 - val_accuracy: 0.5846\n","Epoch 22/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1435 - accuracy: 0.5416 - val_loss: 1.1145 - val_accuracy: 0.6009\n","Epoch 23/50\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1365 - accuracy: 0.5517 - val_loss: 1.1061 - val_accuracy: 0.5965\n","Epoch 24/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1403 - accuracy: 0.5544 - val_loss: 1.1061 - val_accuracy: 0.5840\n","Epoch 25/50\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1442 - accuracy: 0.5478 - val_loss: 1.1093 - val_accuracy: 0.6009\n","Epoch 26/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1386 - accuracy: 0.5527 - val_loss: 1.1035 - val_accuracy: 0.6046\n","Epoch 27/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1415 - accuracy: 0.5502 - val_loss: 1.1179 - val_accuracy: 0.5965\n","Epoch 28/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1437 - accuracy: 0.5545 - val_loss: 1.1031 - val_accuracy: 0.6027\n","Epoch 29/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1329 - accuracy: 0.5547 - val_loss: 1.0990 - val_accuracy: 0.5996\n","Epoch 30/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1361 - accuracy: 0.5622 - val_loss: 1.1057 - val_accuracy: 0.5978\n","Epoch 31/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1347 - accuracy: 0.5609 - val_loss: 1.0970 - val_accuracy: 0.6040\n","Epoch 32/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1329 - accuracy: 0.5581 - val_loss: 1.1161 - val_accuracy: 0.5953\n","Epoch 33/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1416 - accuracy: 0.5591 - val_loss: 1.1071 - val_accuracy: 0.6077\n","Epoch 34/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1314 - accuracy: 0.5584 - val_loss: 1.0970 - val_accuracy: 0.6027\n","Epoch 35/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1268 - accuracy: 0.5628 - val_loss: 1.0923 - val_accuracy: 0.6077\n","Epoch 36/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1335 - accuracy: 0.5598 - val_loss: 1.0974 - val_accuracy: 0.6021\n","Epoch 37/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1274 - accuracy: 0.5592 - val_loss: 1.0912 - val_accuracy: 0.6059\n","Epoch 38/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1409 - accuracy: 0.5575 - val_loss: 1.0993 - val_accuracy: 0.6077\n","Epoch 39/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1360 - accuracy: 0.5636 - val_loss: 1.0966 - val_accuracy: 0.6071\n","Epoch 40/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1284 - accuracy: 0.5725 - val_loss: 1.0927 - val_accuracy: 0.6065\n","Epoch 41/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1312 - accuracy: 0.5681 - val_loss: 1.0895 - val_accuracy: 0.6077\n","Epoch 42/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1237 - accuracy: 0.5706 - val_loss: 1.0977 - val_accuracy: 0.6046\n","Epoch 43/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1282 - accuracy: 0.5705 - val_loss: 1.1007 - val_accuracy: 0.6046\n","Epoch 44/50\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1249 - accuracy: 0.5719 - val_loss: 1.0905 - val_accuracy: 0.6046\n","Epoch 45/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1244 - accuracy: 0.5814 - val_loss: 1.0905 - val_accuracy: 0.6052\n","Epoch 46/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1257 - accuracy: 0.5745 - val_loss: 1.0927 - val_accuracy: 0.6109\n","Epoch 47/50\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1225 - accuracy: 0.5700 - val_loss: 1.0864 - val_accuracy: 0.6046\n","Epoch 48/50\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1175 - accuracy: 0.5731 - val_loss: 1.0900 - val_accuracy: 0.6015\n","Epoch 49/50\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1222 - accuracy: 0.5678 - val_loss: 1.0941 - val_accuracy: 0.6115\n","Epoch 50/50\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1191 - accuracy: 0.5747 - val_loss: 1.0854 - val_accuracy: 0.6115\n","1601/1601 [==============================] - 0s 98us/step\n","Loss=1.0853539136407675, Acc=0.6114928126335144\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GocoJOOgq5FM","colab_type":"text"},"source":["Dropout con regularización L1+L2 y batch_size a 128 con un accuracy entre train y validation con mejores resultados, exactamente un 57.47% y 61.15% respectivamente, e incluso es mejor en validation pero observamos que el modelo aún no generaliza bien. \n","\n","```\n","Epoch 50/50\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1191 - accuracy: 0.5747 - val_loss: 1.0854 - val_accuracy: 0.6115\n","1601/1601 [==============================] - 0s 98us/step\n","Loss=1.0853539136407675, Acc=0.6114928126335144\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"klhterR7CWCb","colab_type":"text"},"source":["Entrenamos el modelo anterior (MLP con Dropout + regularización L1 +L2 y batch size a 128) 200 épocas"]},{"cell_type":"code","metadata":{"id":"O4PP7KpXCSWd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592829704934,"user_tz":-120,"elapsed":67254,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"67542b2c-f9de-493a-93a7-4ff0c2fb1df5"},"source":["# Etapa de clasificación (capas densas con L1_L2 +dropout+softmax)\n","# Modelo para el problema de clasificación (función de perdida categorical_crossentropy y metrica accuracy)\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.regularizers import l1_l2\n","from keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l1_l2(0.01)))\n","model.add(Dropout(0.2))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(5, activation='softmax'))\n","\n","# sparse_categorical_crossentropy es exactamente igual que categorical_crossentropy,\n","# solo que admite enteros en vez de onehot a la entrada\n","opt = Adam(lr=1e-3, decay=1e-4)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_val, y_val),\n","          epochs=200,\n","          batch_size=128)\n","\n","loss, acc = model.evaluate(X_val, y_val)\n","print(f'Loss={loss}, Acc={acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 6400 samples, validate on 1601 samples\n","Epoch 1/200\n","6400/6400 [==============================] - 2s 277us/step - loss: 12.1573 - accuracy: 0.4330 - val_loss: 6.0619 - val_accuracy: 0.5122\n","Epoch 2/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 3.1222 - accuracy: 0.4967 - val_loss: 1.3741 - val_accuracy: 0.5122\n","Epoch 3/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.2443 - accuracy: 0.5008 - val_loss: 1.1705 - val_accuracy: 0.5122\n","Epoch 4/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1817 - accuracy: 0.4972 - val_loss: 1.1664 - val_accuracy: 0.5122\n","Epoch 5/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1797 - accuracy: 0.4977 - val_loss: 1.1683 - val_accuracy: 0.5122\n","Epoch 6/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1802 - accuracy: 0.5033 - val_loss: 1.1675 - val_accuracy: 0.5122\n","Epoch 7/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1799 - accuracy: 0.4961 - val_loss: 1.1625 - val_accuracy: 0.5122\n","Epoch 8/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1775 - accuracy: 0.5028 - val_loss: 1.1627 - val_accuracy: 0.5122\n","Epoch 9/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1753 - accuracy: 0.5022 - val_loss: 1.1591 - val_accuracy: 0.5122\n","Epoch 10/200\n","6400/6400 [==============================] - 0s 50us/step - loss: 1.1738 - accuracy: 0.5072 - val_loss: 1.1525 - val_accuracy: 0.5122\n","Epoch 11/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1713 - accuracy: 0.5100 - val_loss: 1.1455 - val_accuracy: 0.5122\n","Epoch 12/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1573 - accuracy: 0.5281 - val_loss: 1.1382 - val_accuracy: 0.5203\n","Epoch 13/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1577 - accuracy: 0.5362 - val_loss: 1.1306 - val_accuracy: 0.5784\n","Epoch 14/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1519 - accuracy: 0.5436 - val_loss: 1.1220 - val_accuracy: 0.5796\n","Epoch 15/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1553 - accuracy: 0.5423 - val_loss: 1.1209 - val_accuracy: 0.5840\n","Epoch 16/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1476 - accuracy: 0.5541 - val_loss: 1.1203 - val_accuracy: 0.5765\n","Epoch 17/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1519 - accuracy: 0.5525 - val_loss: 1.1192 - val_accuracy: 0.5965\n","Epoch 18/200\n","6400/6400 [==============================] - 0s 50us/step - loss: 1.1443 - accuracy: 0.5536 - val_loss: 1.1121 - val_accuracy: 0.5871\n","Epoch 19/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1476 - accuracy: 0.5595 - val_loss: 1.1128 - val_accuracy: 0.5971\n","Epoch 20/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1387 - accuracy: 0.5658 - val_loss: 1.1056 - val_accuracy: 0.5915\n","Epoch 21/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1430 - accuracy: 0.5627 - val_loss: 1.1118 - val_accuracy: 0.6002\n","Epoch 22/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1441 - accuracy: 0.5562 - val_loss: 1.1116 - val_accuracy: 0.6027\n","Epoch 23/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1364 - accuracy: 0.5667 - val_loss: 1.1034 - val_accuracy: 0.6021\n","Epoch 24/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1404 - accuracy: 0.5609 - val_loss: 1.1029 - val_accuracy: 0.6071\n","Epoch 25/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1311 - accuracy: 0.5659 - val_loss: 1.1138 - val_accuracy: 0.5978\n","Epoch 26/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1346 - accuracy: 0.5622 - val_loss: 1.0973 - val_accuracy: 0.6027\n","Epoch 27/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1336 - accuracy: 0.5688 - val_loss: 1.1001 - val_accuracy: 0.6034\n","Epoch 28/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1307 - accuracy: 0.5691 - val_loss: 1.0966 - val_accuracy: 0.5990\n","Epoch 29/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1328 - accuracy: 0.5702 - val_loss: 1.1119 - val_accuracy: 0.6034\n","Epoch 30/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1345 - accuracy: 0.5723 - val_loss: 1.0948 - val_accuracy: 0.6027\n","Epoch 31/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1310 - accuracy: 0.5773 - val_loss: 1.0997 - val_accuracy: 0.6034\n","Epoch 32/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1356 - accuracy: 0.5673 - val_loss: 1.0974 - val_accuracy: 0.6046\n","Epoch 33/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1300 - accuracy: 0.5675 - val_loss: 1.1102 - val_accuracy: 0.6040\n","Epoch 34/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1265 - accuracy: 0.5709 - val_loss: 1.1116 - val_accuracy: 0.5984\n","Epoch 35/200\n","6400/6400 [==============================] - 0s 42us/step - loss: 1.1323 - accuracy: 0.5655 - val_loss: 1.1002 - val_accuracy: 0.5978\n","Epoch 36/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1278 - accuracy: 0.5714 - val_loss: 1.0921 - val_accuracy: 0.6134\n","Epoch 37/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1243 - accuracy: 0.5759 - val_loss: 1.0892 - val_accuracy: 0.6027\n","Epoch 38/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1257 - accuracy: 0.5780 - val_loss: 1.0897 - val_accuracy: 0.6102\n","Epoch 39/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1273 - accuracy: 0.5755 - val_loss: 1.0970 - val_accuracy: 0.6115\n","Epoch 40/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1268 - accuracy: 0.5763 - val_loss: 1.1040 - val_accuracy: 0.6040\n","Epoch 41/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1247 - accuracy: 0.5734 - val_loss: 1.1001 - val_accuracy: 0.5878\n","Epoch 42/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1231 - accuracy: 0.5691 - val_loss: 1.0946 - val_accuracy: 0.6115\n","Epoch 43/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1199 - accuracy: 0.5763 - val_loss: 1.0867 - val_accuracy: 0.6146\n","Epoch 44/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1365 - accuracy: 0.5678 - val_loss: 1.0908 - val_accuracy: 0.6052\n","Epoch 45/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1250 - accuracy: 0.5794 - val_loss: 1.0905 - val_accuracy: 0.6052\n","Epoch 46/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1293 - accuracy: 0.5738 - val_loss: 1.0957 - val_accuracy: 0.6027\n","Epoch 47/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1256 - accuracy: 0.5738 - val_loss: 1.0902 - val_accuracy: 0.6121\n","Epoch 48/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1167 - accuracy: 0.5745 - val_loss: 1.0869 - val_accuracy: 0.6065\n","Epoch 49/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1259 - accuracy: 0.5730 - val_loss: 1.0853 - val_accuracy: 0.6140\n","Epoch 50/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1244 - accuracy: 0.5755 - val_loss: 1.0870 - val_accuracy: 0.6071\n","Epoch 51/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1192 - accuracy: 0.5791 - val_loss: 1.0819 - val_accuracy: 0.6165\n","Epoch 52/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1201 - accuracy: 0.5725 - val_loss: 1.0934 - val_accuracy: 0.6015\n","Epoch 53/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1204 - accuracy: 0.5802 - val_loss: 1.0869 - val_accuracy: 0.6046\n","Epoch 54/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1233 - accuracy: 0.5764 - val_loss: 1.0909 - val_accuracy: 0.6027\n","Epoch 55/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1174 - accuracy: 0.5825 - val_loss: 1.0880 - val_accuracy: 0.6184\n","Epoch 56/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1106 - accuracy: 0.5803 - val_loss: 1.0837 - val_accuracy: 0.6190\n","Epoch 57/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1229 - accuracy: 0.5759 - val_loss: 1.0864 - val_accuracy: 0.6115\n","Epoch 58/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1185 - accuracy: 0.5770 - val_loss: 1.1353 - val_accuracy: 0.5572\n","Epoch 59/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1231 - accuracy: 0.5745 - val_loss: 1.1212 - val_accuracy: 0.5978\n","Epoch 60/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1229 - accuracy: 0.5795 - val_loss: 1.0964 - val_accuracy: 0.5996\n","Epoch 61/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1149 - accuracy: 0.5733 - val_loss: 1.1052 - val_accuracy: 0.5953\n","Epoch 62/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1220 - accuracy: 0.5739 - val_loss: 1.0900 - val_accuracy: 0.6109\n","Epoch 63/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1137 - accuracy: 0.5794 - val_loss: 1.0878 - val_accuracy: 0.6127\n","Epoch 64/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1126 - accuracy: 0.5784 - val_loss: 1.0866 - val_accuracy: 0.6109\n","Epoch 65/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1162 - accuracy: 0.5808 - val_loss: 1.0888 - val_accuracy: 0.6065\n","Epoch 66/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1130 - accuracy: 0.5791 - val_loss: 1.0965 - val_accuracy: 0.6096\n","Epoch 67/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1201 - accuracy: 0.5783 - val_loss: 1.0856 - val_accuracy: 0.6040\n","Epoch 68/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1137 - accuracy: 0.5773 - val_loss: 1.0839 - val_accuracy: 0.6077\n","Epoch 69/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1175 - accuracy: 0.5784 - val_loss: 1.0957 - val_accuracy: 0.5996\n","Epoch 70/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1178 - accuracy: 0.5816 - val_loss: 1.0932 - val_accuracy: 0.5971\n","Epoch 71/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1073 - accuracy: 0.5869 - val_loss: 1.0918 - val_accuracy: 0.6052\n","Epoch 72/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1106 - accuracy: 0.5800 - val_loss: 1.0808 - val_accuracy: 0.6177\n","Epoch 73/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1145 - accuracy: 0.5761 - val_loss: 1.0827 - val_accuracy: 0.6115\n","Epoch 74/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1136 - accuracy: 0.5852 - val_loss: 1.0822 - val_accuracy: 0.6096\n","Epoch 75/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1158 - accuracy: 0.5773 - val_loss: 1.0850 - val_accuracy: 0.6034\n","Epoch 76/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1125 - accuracy: 0.5769 - val_loss: 1.0982 - val_accuracy: 0.6084\n","Epoch 77/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1167 - accuracy: 0.5838 - val_loss: 1.0873 - val_accuracy: 0.6096\n","Epoch 78/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1126 - accuracy: 0.5788 - val_loss: 1.0834 - val_accuracy: 0.6127\n","Epoch 79/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1162 - accuracy: 0.5780 - val_loss: 1.0851 - val_accuracy: 0.6165\n","Epoch 80/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1097 - accuracy: 0.5852 - val_loss: 1.0815 - val_accuracy: 0.6109\n","Epoch 81/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1119 - accuracy: 0.5841 - val_loss: 1.0941 - val_accuracy: 0.6071\n","Epoch 82/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1081 - accuracy: 0.5844 - val_loss: 1.0892 - val_accuracy: 0.6146\n","Epoch 83/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1165 - accuracy: 0.5780 - val_loss: 1.0885 - val_accuracy: 0.6090\n","Epoch 84/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1108 - accuracy: 0.5769 - val_loss: 1.0799 - val_accuracy: 0.6159\n","Epoch 85/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1210 - accuracy: 0.5763 - val_loss: 1.1116 - val_accuracy: 0.5884\n","Epoch 86/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1178 - accuracy: 0.5781 - val_loss: 1.0873 - val_accuracy: 0.6134\n","Epoch 87/200\n","6400/6400 [==============================] - 0s 43us/step - loss: 1.1085 - accuracy: 0.5881 - val_loss: 1.1097 - val_accuracy: 0.5765\n","Epoch 88/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1205 - accuracy: 0.5747 - val_loss: 1.0943 - val_accuracy: 0.6065\n","Epoch 89/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1061 - accuracy: 0.5844 - val_loss: 1.0880 - val_accuracy: 0.6065\n","Epoch 90/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1090 - accuracy: 0.5823 - val_loss: 1.0830 - val_accuracy: 0.6127\n","Epoch 91/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1109 - accuracy: 0.5763 - val_loss: 1.0939 - val_accuracy: 0.5815\n","Epoch 92/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1142 - accuracy: 0.5773 - val_loss: 1.0793 - val_accuracy: 0.6134\n","Epoch 93/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1085 - accuracy: 0.5856 - val_loss: 1.0878 - val_accuracy: 0.6077\n","Epoch 94/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1090 - accuracy: 0.5828 - val_loss: 1.0837 - val_accuracy: 0.6127\n","Epoch 95/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1039 - accuracy: 0.5839 - val_loss: 1.0752 - val_accuracy: 0.6121\n","Epoch 96/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1033 - accuracy: 0.5902 - val_loss: 1.0767 - val_accuracy: 0.6084\n","Epoch 97/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1067 - accuracy: 0.5814 - val_loss: 1.0819 - val_accuracy: 0.6027\n","Epoch 98/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1197 - accuracy: 0.5698 - val_loss: 1.0983 - val_accuracy: 0.6002\n","Epoch 99/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1159 - accuracy: 0.5783 - val_loss: 1.0921 - val_accuracy: 0.6059\n","Epoch 100/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1206 - accuracy: 0.5778 - val_loss: 1.0847 - val_accuracy: 0.6109\n","Epoch 101/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1035 - accuracy: 0.5900 - val_loss: 1.0890 - val_accuracy: 0.6002\n","Epoch 102/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1135 - accuracy: 0.5750 - val_loss: 1.0849 - val_accuracy: 0.5971\n","Epoch 103/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1092 - accuracy: 0.5838 - val_loss: 1.0822 - val_accuracy: 0.6127\n","Epoch 104/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1091 - accuracy: 0.5809 - val_loss: 1.1151 - val_accuracy: 0.5821\n","Epoch 105/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1170 - accuracy: 0.5764 - val_loss: 1.0814 - val_accuracy: 0.6121\n","Epoch 106/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1234 - accuracy: 0.5711 - val_loss: 1.0980 - val_accuracy: 0.6027\n","Epoch 107/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1169 - accuracy: 0.5727 - val_loss: 1.0783 - val_accuracy: 0.6059\n","Epoch 108/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1050 - accuracy: 0.5875 - val_loss: 1.1000 - val_accuracy: 0.5890\n","Epoch 109/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1037 - accuracy: 0.5820 - val_loss: 1.0781 - val_accuracy: 0.6059\n","Epoch 110/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1074 - accuracy: 0.5816 - val_loss: 1.1106 - val_accuracy: 0.5821\n","Epoch 111/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1073 - accuracy: 0.5747 - val_loss: 1.0816 - val_accuracy: 0.6077\n","Epoch 112/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1127 - accuracy: 0.5775 - val_loss: 1.0801 - val_accuracy: 0.6065\n","Epoch 113/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1028 - accuracy: 0.5827 - val_loss: 1.0763 - val_accuracy: 0.6152\n","Epoch 114/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.0989 - accuracy: 0.5852 - val_loss: 1.0796 - val_accuracy: 0.6102\n","Epoch 115/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1033 - accuracy: 0.5839 - val_loss: 1.1090 - val_accuracy: 0.5746\n","Epoch 116/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1094 - accuracy: 0.5792 - val_loss: 1.0752 - val_accuracy: 0.6077\n","Epoch 117/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1072 - accuracy: 0.5783 - val_loss: 1.0812 - val_accuracy: 0.6165\n","Epoch 118/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1171 - accuracy: 0.5752 - val_loss: 1.1133 - val_accuracy: 0.5821\n","Epoch 119/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1170 - accuracy: 0.5719 - val_loss: 1.0804 - val_accuracy: 0.6102\n","Epoch 120/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.0987 - accuracy: 0.5875 - val_loss: 1.0750 - val_accuracy: 0.6102\n","Epoch 121/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1011 - accuracy: 0.5875 - val_loss: 1.0889 - val_accuracy: 0.6002\n","Epoch 122/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1054 - accuracy: 0.5820 - val_loss: 1.0854 - val_accuracy: 0.6102\n","Epoch 123/200\n","6400/6400 [==============================] - 0s 50us/step - loss: 1.1039 - accuracy: 0.5803 - val_loss: 1.0736 - val_accuracy: 0.6115\n","Epoch 124/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1038 - accuracy: 0.5881 - val_loss: 1.0745 - val_accuracy: 0.6121\n","Epoch 125/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0992 - accuracy: 0.5888 - val_loss: 1.0795 - val_accuracy: 0.6177\n","Epoch 126/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1064 - accuracy: 0.5814 - val_loss: 1.0847 - val_accuracy: 0.6052\n","Epoch 127/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1037 - accuracy: 0.5872 - val_loss: 1.0791 - val_accuracy: 0.6140\n","Epoch 128/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1030 - accuracy: 0.5861 - val_loss: 1.0770 - val_accuracy: 0.6102\n","Epoch 129/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1092 - accuracy: 0.5802 - val_loss: 1.0924 - val_accuracy: 0.6065\n","Epoch 130/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1030 - accuracy: 0.5867 - val_loss: 1.0778 - val_accuracy: 0.6159\n","Epoch 131/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0997 - accuracy: 0.5897 - val_loss: 1.1317 - val_accuracy: 0.5740\n","Epoch 132/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1210 - accuracy: 0.5784 - val_loss: 1.0827 - val_accuracy: 0.6109\n","Epoch 133/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1050 - accuracy: 0.5767 - val_loss: 1.0762 - val_accuracy: 0.6102\n","Epoch 134/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1058 - accuracy: 0.5867 - val_loss: 1.1213 - val_accuracy: 0.5765\n","Epoch 135/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1119 - accuracy: 0.5772 - val_loss: 1.0891 - val_accuracy: 0.6021\n","Epoch 136/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1001 - accuracy: 0.5866 - val_loss: 1.0764 - val_accuracy: 0.6127\n","Epoch 137/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1077 - accuracy: 0.5794 - val_loss: 1.0961 - val_accuracy: 0.5890\n","Epoch 138/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1083 - accuracy: 0.5820 - val_loss: 1.0981 - val_accuracy: 0.6065\n","Epoch 139/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1140 - accuracy: 0.5716 - val_loss: 1.0778 - val_accuracy: 0.6202\n","Epoch 140/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0979 - accuracy: 0.5881 - val_loss: 1.0815 - val_accuracy: 0.6121\n","Epoch 141/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1026 - accuracy: 0.5863 - val_loss: 1.0736 - val_accuracy: 0.6152\n","Epoch 142/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1028 - accuracy: 0.5845 - val_loss: 1.0886 - val_accuracy: 0.6009\n","Epoch 143/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1037 - accuracy: 0.5852 - val_loss: 1.0787 - val_accuracy: 0.6140\n","Epoch 144/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1029 - accuracy: 0.5845 - val_loss: 1.0890 - val_accuracy: 0.6071\n","Epoch 145/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1045 - accuracy: 0.5820 - val_loss: 1.0848 - val_accuracy: 0.6077\n","Epoch 146/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1065 - accuracy: 0.5841 - val_loss: 1.0775 - val_accuracy: 0.6165\n","Epoch 147/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1042 - accuracy: 0.5819 - val_loss: 1.0766 - val_accuracy: 0.6127\n","Epoch 148/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1005 - accuracy: 0.5877 - val_loss: 1.0755 - val_accuracy: 0.6234\n","Epoch 149/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1020 - accuracy: 0.5852 - val_loss: 1.0778 - val_accuracy: 0.6096\n","Epoch 150/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1061 - accuracy: 0.5845 - val_loss: 1.1152 - val_accuracy: 0.5840\n","Epoch 151/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1127 - accuracy: 0.5822 - val_loss: 1.0787 - val_accuracy: 0.6171\n","Epoch 152/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1028 - accuracy: 0.5848 - val_loss: 1.0819 - val_accuracy: 0.6109\n","Epoch 153/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0992 - accuracy: 0.5878 - val_loss: 1.0846 - val_accuracy: 0.6152\n","Epoch 154/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1008 - accuracy: 0.5898 - val_loss: 1.0794 - val_accuracy: 0.6065\n","Epoch 155/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1054 - accuracy: 0.5825 - val_loss: 1.0767 - val_accuracy: 0.6171\n","Epoch 156/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1042 - accuracy: 0.5920 - val_loss: 1.0865 - val_accuracy: 0.5984\n","Epoch 157/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1004 - accuracy: 0.5955 - val_loss: 1.0816 - val_accuracy: 0.6096\n","Epoch 158/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1050 - accuracy: 0.5839 - val_loss: 1.1079 - val_accuracy: 0.5859\n","Epoch 159/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1159 - accuracy: 0.5863 - val_loss: 1.0771 - val_accuracy: 0.6159\n","Epoch 160/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1038 - accuracy: 0.5920 - val_loss: 1.0723 - val_accuracy: 0.6165\n","Epoch 161/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.0999 - accuracy: 0.5897 - val_loss: 1.0945 - val_accuracy: 0.5996\n","Epoch 162/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1037 - accuracy: 0.5763 - val_loss: 1.0925 - val_accuracy: 0.5984\n","Epoch 163/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1083 - accuracy: 0.5917 - val_loss: 1.0774 - val_accuracy: 0.6115\n","Epoch 164/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1000 - accuracy: 0.5902 - val_loss: 1.0937 - val_accuracy: 0.5940\n","Epoch 165/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1038 - accuracy: 0.5866 - val_loss: 1.0792 - val_accuracy: 0.6177\n","Epoch 166/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.0972 - accuracy: 0.5908 - val_loss: 1.0828 - val_accuracy: 0.6084\n","Epoch 167/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1120 - accuracy: 0.5838 - val_loss: 1.0779 - val_accuracy: 0.6027\n","Epoch 168/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1034 - accuracy: 0.5866 - val_loss: 1.0758 - val_accuracy: 0.6209\n","Epoch 169/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0962 - accuracy: 0.5930 - val_loss: 1.0736 - val_accuracy: 0.6152\n","Epoch 170/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.0940 - accuracy: 0.5959 - val_loss: 1.0824 - val_accuracy: 0.6184\n","Epoch 171/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.0986 - accuracy: 0.5913 - val_loss: 1.1193 - val_accuracy: 0.5815\n","Epoch 172/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1049 - accuracy: 0.5802 - val_loss: 1.0753 - val_accuracy: 0.6096\n","Epoch 173/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1056 - accuracy: 0.5822 - val_loss: 1.0848 - val_accuracy: 0.6152\n","Epoch 174/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1026 - accuracy: 0.5905 - val_loss: 1.0876 - val_accuracy: 0.5996\n","Epoch 175/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1012 - accuracy: 0.5925 - val_loss: 1.0891 - val_accuracy: 0.6102\n","Epoch 176/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1070 - accuracy: 0.5831 - val_loss: 1.0802 - val_accuracy: 0.6090\n","Epoch 177/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1025 - accuracy: 0.5864 - val_loss: 1.0795 - val_accuracy: 0.6090\n","Epoch 178/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1081 - accuracy: 0.5833 - val_loss: 1.0833 - val_accuracy: 0.6071\n","Epoch 179/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0966 - accuracy: 0.5936 - val_loss: 1.0761 - val_accuracy: 0.6177\n","Epoch 180/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1023 - accuracy: 0.5864 - val_loss: 1.1009 - val_accuracy: 0.5953\n","Epoch 181/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1117 - accuracy: 0.5825 - val_loss: 1.0958 - val_accuracy: 0.5921\n","Epoch 182/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1050 - accuracy: 0.5827 - val_loss: 1.0832 - val_accuracy: 0.6071\n","Epoch 183/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1092 - accuracy: 0.5850 - val_loss: 1.0803 - val_accuracy: 0.6159\n","Epoch 184/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.1035 - accuracy: 0.5883 - val_loss: 1.0785 - val_accuracy: 0.6140\n","Epoch 185/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1087 - accuracy: 0.5861 - val_loss: 1.0877 - val_accuracy: 0.6084\n","Epoch 186/200\n","6400/6400 [==============================] - 0s 44us/step - loss: 1.1011 - accuracy: 0.5989 - val_loss: 1.0827 - val_accuracy: 0.6121\n","Epoch 187/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.0988 - accuracy: 0.5889 - val_loss: 1.0855 - val_accuracy: 0.6127\n","Epoch 188/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0964 - accuracy: 0.5884 - val_loss: 1.0788 - val_accuracy: 0.6159\n","Epoch 189/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.0983 - accuracy: 0.5855 - val_loss: 1.0840 - val_accuracy: 0.6121\n","Epoch 190/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1016 - accuracy: 0.5895 - val_loss: 1.0857 - val_accuracy: 0.6040\n","Epoch 191/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1037 - accuracy: 0.5855 - val_loss: 1.0973 - val_accuracy: 0.6002\n","Epoch 192/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1067 - accuracy: 0.5841 - val_loss: 1.0736 - val_accuracy: 0.6096\n","Epoch 193/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1019 - accuracy: 0.5872 - val_loss: 1.0747 - val_accuracy: 0.6109\n","Epoch 194/200\n","6400/6400 [==============================] - 0s 49us/step - loss: 1.1107 - accuracy: 0.5788 - val_loss: 1.0910 - val_accuracy: 0.6065\n","Epoch 195/200\n","6400/6400 [==============================] - 0s 46us/step - loss: 1.1035 - accuracy: 0.5934 - val_loss: 1.0777 - val_accuracy: 0.6146\n","Epoch 196/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1061 - accuracy: 0.5823 - val_loss: 1.0926 - val_accuracy: 0.5946\n","Epoch 197/200\n","6400/6400 [==============================] - 0s 48us/step - loss: 1.0946 - accuracy: 0.5908 - val_loss: 1.0892 - val_accuracy: 0.6071\n","Epoch 198/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.0970 - accuracy: 0.5934 - val_loss: 1.0838 - val_accuracy: 0.6177\n","Epoch 199/200\n","6400/6400 [==============================] - 0s 47us/step - loss: 1.1056 - accuracy: 0.5875 - val_loss: 1.0839 - val_accuracy: 0.6115\n","Epoch 200/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1009 - accuracy: 0.5883 - val_loss: 1.0847 - val_accuracy: 0.6084\n","1601/1601 [==============================] - 0s 111us/step\n","Loss=1.084744718505173, Acc=0.608369767665863\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mOq7wW8vDJ7C","colab_type":"text"},"source":["Prácticamente no ha mejorado mucho, concretamente el accuracy en train sube aproximadamente un 1% y en validation empeora aproximadamente un 0.5%\n","\n","50 épocas: loss: 1.1191 - accuracy: 0.5747 - val_loss: 1.0854 - val_accuracy: 0.6115\n","\n","200 épocas: loss: 1.1009 - accuracy: 0.5883 - val_loss: 1.0847 - val_accuracy: 0.6084\n","\n","```\n","Epoch 200/200\n","6400/6400 [==============================] - 0s 45us/step - loss: 1.1009 - accuracy: 0.5883 - val_loss: 1.0847 - val_accuracy: 0.6084\n","1601/1601 [==============================] - 0s 111us/step\n","Loss=1.084744718505173, Acc=0.608369767665863\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z5PamMMtD6g3","colab_type":"text"},"source":["Tomamos el modelo inicial con un 99% y 55% de accuracy en train y validation respectivamente y ahora entrenamos el modelo a 200 epochs "]},{"cell_type":"code","metadata":{"id":"1Ed_Yms9rvsz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592830534352,"user_tz":-120,"elapsed":76061,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"781a10ac-c34c-4bc3-8365-db31576d48bc"},"source":["# Volvemos al modelo inicial para intentar mejorar el accuracy de validation con mayor entrenamiento (epochs=200) y con los hiperparámetros\n","# Modelo para el problema de clasificación (función de perdida categorical_crossentropy y metrica accuracy)\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","\n","\n","model = Sequential()\n","model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(5, activation='softmax'))\n","\n","# sparse_categorical_crossentropy es exactamente igual que categorical_crossentropy,\n","# solo que admite enteros en vez de onehot a la entrada\n","opt = Adam(lr=1e-3, decay=1e-3)\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_val, y_val),\n","          epochs=200,\n","          batch_size=32)\n","\n","loss, acc = model.evaluate(X_val, y_val)\n","print(f'Loss={loss}, Acc={acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 6400 samples, validate on 1601 samples\n","Epoch 1/200\n","6400/6400 [==============================] - 1s 106us/step - loss: 1.0979 - accuracy: 0.5448 - val_loss: 1.0158 - val_accuracy: 0.6009\n","Epoch 2/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.9937 - accuracy: 0.6022 - val_loss: 0.9888 - val_accuracy: 0.6102\n","Epoch 3/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.9627 - accuracy: 0.6119 - val_loss: 0.9846 - val_accuracy: 0.6202\n","Epoch 4/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.9409 - accuracy: 0.6211 - val_loss: 0.9926 - val_accuracy: 0.6165\n","Epoch 5/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.9256 - accuracy: 0.6266 - val_loss: 0.9959 - val_accuracy: 0.6090\n","Epoch 6/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.9097 - accuracy: 0.6323 - val_loss: 0.9911 - val_accuracy: 0.6127\n","Epoch 7/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.8941 - accuracy: 0.6366 - val_loss: 0.9938 - val_accuracy: 0.6109\n","Epoch 8/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.8801 - accuracy: 0.6463 - val_loss: 1.0141 - val_accuracy: 0.6046\n","Epoch 9/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.8684 - accuracy: 0.6503 - val_loss: 1.0032 - val_accuracy: 0.6040\n","Epoch 10/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.8539 - accuracy: 0.6573 - val_loss: 1.0072 - val_accuracy: 0.6121\n","Epoch 11/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.8362 - accuracy: 0.6648 - val_loss: 1.0185 - val_accuracy: 0.6065\n","Epoch 12/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.8248 - accuracy: 0.6733 - val_loss: 1.0178 - val_accuracy: 0.6065\n","Epoch 13/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.8076 - accuracy: 0.6861 - val_loss: 1.0299 - val_accuracy: 0.5946\n","Epoch 14/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.7930 - accuracy: 0.6895 - val_loss: 1.0368 - val_accuracy: 0.6040\n","Epoch 15/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.7809 - accuracy: 0.6952 - val_loss: 1.0640 - val_accuracy: 0.6059\n","Epoch 16/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.7657 - accuracy: 0.7045 - val_loss: 1.0543 - val_accuracy: 0.6021\n","Epoch 17/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.7516 - accuracy: 0.7119 - val_loss: 1.0601 - val_accuracy: 0.6021\n","Epoch 18/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.7392 - accuracy: 0.7163 - val_loss: 1.0782 - val_accuracy: 0.6021\n","Epoch 19/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.7280 - accuracy: 0.7197 - val_loss: 1.0754 - val_accuracy: 0.6009\n","Epoch 20/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.7152 - accuracy: 0.7278 - val_loss: 1.0902 - val_accuracy: 0.5871\n","Epoch 21/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.7033 - accuracy: 0.7345 - val_loss: 1.0909 - val_accuracy: 0.5965\n","Epoch 22/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.6918 - accuracy: 0.7448 - val_loss: 1.1021 - val_accuracy: 0.5971\n","Epoch 23/200\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.6831 - accuracy: 0.7439 - val_loss: 1.1097 - val_accuracy: 0.5946\n","Epoch 24/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.6717 - accuracy: 0.7558 - val_loss: 1.1172 - val_accuracy: 0.5946\n","Epoch 25/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.6615 - accuracy: 0.7577 - val_loss: 1.1264 - val_accuracy: 0.5959\n","Epoch 26/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.6517 - accuracy: 0.7634 - val_loss: 1.1346 - val_accuracy: 0.5834\n","Epoch 27/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.6421 - accuracy: 0.7695 - val_loss: 1.1415 - val_accuracy: 0.5884\n","Epoch 28/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.6344 - accuracy: 0.7722 - val_loss: 1.1499 - val_accuracy: 0.5853\n","Epoch 29/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.6252 - accuracy: 0.7770 - val_loss: 1.1606 - val_accuracy: 0.5940\n","Epoch 30/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.6154 - accuracy: 0.7859 - val_loss: 1.1688 - val_accuracy: 0.5759\n","Epoch 31/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.6089 - accuracy: 0.7812 - val_loss: 1.1731 - val_accuracy: 0.5809\n","Epoch 32/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.6009 - accuracy: 0.7884 - val_loss: 1.1851 - val_accuracy: 0.5753\n","Epoch 33/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.5929 - accuracy: 0.7936 - val_loss: 1.1906 - val_accuracy: 0.5715\n","Epoch 34/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.5857 - accuracy: 0.7969 - val_loss: 1.1957 - val_accuracy: 0.5871\n","Epoch 35/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.5785 - accuracy: 0.8012 - val_loss: 1.2059 - val_accuracy: 0.5765\n","Epoch 36/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.5711 - accuracy: 0.8037 - val_loss: 1.2141 - val_accuracy: 0.5678\n","Epoch 37/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.5640 - accuracy: 0.8044 - val_loss: 1.2232 - val_accuracy: 0.5671\n","Epoch 38/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.5575 - accuracy: 0.8061 - val_loss: 1.2317 - val_accuracy: 0.5753\n","Epoch 39/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.5526 - accuracy: 0.8127 - val_loss: 1.2373 - val_accuracy: 0.5721\n","Epoch 40/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.5446 - accuracy: 0.8136 - val_loss: 1.2437 - val_accuracy: 0.5678\n","Epoch 41/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.5390 - accuracy: 0.8213 - val_loss: 1.2554 - val_accuracy: 0.5778\n","Epoch 42/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.5323 - accuracy: 0.8213 - val_loss: 1.2575 - val_accuracy: 0.5715\n","Epoch 43/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.5272 - accuracy: 0.8261 - val_loss: 1.2654 - val_accuracy: 0.5746\n","Epoch 44/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.5208 - accuracy: 0.8283 - val_loss: 1.2716 - val_accuracy: 0.5659\n","Epoch 45/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.5149 - accuracy: 0.8327 - val_loss: 1.2851 - val_accuracy: 0.5653\n","Epoch 46/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.5113 - accuracy: 0.8330 - val_loss: 1.2902 - val_accuracy: 0.5771\n","Epoch 47/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.5053 - accuracy: 0.8341 - val_loss: 1.2969 - val_accuracy: 0.5665\n","Epoch 48/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.5001 - accuracy: 0.8389 - val_loss: 1.3054 - val_accuracy: 0.5590\n","Epoch 49/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.4949 - accuracy: 0.8409 - val_loss: 1.3104 - val_accuracy: 0.5709\n","Epoch 50/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.4896 - accuracy: 0.8430 - val_loss: 1.3207 - val_accuracy: 0.5671\n","Epoch 51/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.4865 - accuracy: 0.8431 - val_loss: 1.3268 - val_accuracy: 0.5671\n","Epoch 52/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.4804 - accuracy: 0.8447 - val_loss: 1.3326 - val_accuracy: 0.5653\n","Epoch 53/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.4763 - accuracy: 0.8459 - val_loss: 1.3404 - val_accuracy: 0.5703\n","Epoch 54/200\n","6400/6400 [==============================] - 0s 62us/step - loss: 0.4712 - accuracy: 0.8483 - val_loss: 1.3439 - val_accuracy: 0.5640\n","Epoch 55/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.4663 - accuracy: 0.8516 - val_loss: 1.3496 - val_accuracy: 0.5572\n","Epoch 56/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.4621 - accuracy: 0.8552 - val_loss: 1.3605 - val_accuracy: 0.5728\n","Epoch 57/200\n","6400/6400 [==============================] - 0s 63us/step - loss: 0.4582 - accuracy: 0.8550 - val_loss: 1.3621 - val_accuracy: 0.5671\n","Epoch 58/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.4539 - accuracy: 0.8572 - val_loss: 1.3718 - val_accuracy: 0.5678\n","Epoch 59/200\n","6400/6400 [==============================] - 0s 64us/step - loss: 0.4502 - accuracy: 0.8566 - val_loss: 1.3792 - val_accuracy: 0.5690\n","Epoch 60/200\n","6400/6400 [==============================] - 0s 62us/step - loss: 0.4463 - accuracy: 0.8594 - val_loss: 1.3855 - val_accuracy: 0.5703\n","Epoch 61/200\n","6400/6400 [==============================] - 0s 63us/step - loss: 0.4424 - accuracy: 0.8597 - val_loss: 1.3894 - val_accuracy: 0.5565\n","Epoch 62/200\n","6400/6400 [==============================] - 0s 65us/step - loss: 0.4377 - accuracy: 0.8642 - val_loss: 1.4038 - val_accuracy: 0.5534\n","Epoch 63/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.4352 - accuracy: 0.8641 - val_loss: 1.4042 - val_accuracy: 0.5609\n","Epoch 64/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.4305 - accuracy: 0.8647 - val_loss: 1.4121 - val_accuracy: 0.5653\n","Epoch 65/200\n","6400/6400 [==============================] - 0s 62us/step - loss: 0.4273 - accuracy: 0.8664 - val_loss: 1.4236 - val_accuracy: 0.5553\n","Epoch 66/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.4236 - accuracy: 0.8684 - val_loss: 1.4235 - val_accuracy: 0.5540\n","Epoch 67/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.4200 - accuracy: 0.8691 - val_loss: 1.4331 - val_accuracy: 0.5565\n","Epoch 68/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.4162 - accuracy: 0.8716 - val_loss: 1.4375 - val_accuracy: 0.5559\n","Epoch 69/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.4135 - accuracy: 0.8702 - val_loss: 1.4454 - val_accuracy: 0.5609\n","Epoch 70/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.4098 - accuracy: 0.8739 - val_loss: 1.4489 - val_accuracy: 0.5584\n","Epoch 71/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.4070 - accuracy: 0.8766 - val_loss: 1.4577 - val_accuracy: 0.5509\n","Epoch 72/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.4035 - accuracy: 0.8764 - val_loss: 1.4601 - val_accuracy: 0.5528\n","Epoch 73/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.4007 - accuracy: 0.8783 - val_loss: 1.4691 - val_accuracy: 0.5590\n","Epoch 74/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3975 - accuracy: 0.8794 - val_loss: 1.4734 - val_accuracy: 0.5565\n","Epoch 75/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.3940 - accuracy: 0.8805 - val_loss: 1.4805 - val_accuracy: 0.5534\n","Epoch 76/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3915 - accuracy: 0.8833 - val_loss: 1.4847 - val_accuracy: 0.5540\n","Epoch 77/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3882 - accuracy: 0.8823 - val_loss: 1.4911 - val_accuracy: 0.5528\n","Epoch 78/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.3855 - accuracy: 0.8841 - val_loss: 1.4961 - val_accuracy: 0.5540\n","Epoch 79/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3823 - accuracy: 0.8842 - val_loss: 1.5016 - val_accuracy: 0.5547\n","Epoch 80/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3791 - accuracy: 0.8867 - val_loss: 1.5111 - val_accuracy: 0.5565\n","Epoch 81/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3762 - accuracy: 0.8870 - val_loss: 1.5138 - val_accuracy: 0.5472\n","Epoch 82/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.3744 - accuracy: 0.8883 - val_loss: 1.5179 - val_accuracy: 0.5578\n","Epoch 83/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.3712 - accuracy: 0.8892 - val_loss: 1.5267 - val_accuracy: 0.5522\n","Epoch 84/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.3683 - accuracy: 0.8908 - val_loss: 1.5313 - val_accuracy: 0.5484\n","Epoch 85/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3661 - accuracy: 0.8911 - val_loss: 1.5388 - val_accuracy: 0.5390\n","Epoch 86/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.3633 - accuracy: 0.8927 - val_loss: 1.5429 - val_accuracy: 0.5497\n","Epoch 87/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3610 - accuracy: 0.8919 - val_loss: 1.5510 - val_accuracy: 0.5397\n","Epoch 88/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3589 - accuracy: 0.8952 - val_loss: 1.5523 - val_accuracy: 0.5459\n","Epoch 89/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3559 - accuracy: 0.8970 - val_loss: 1.5634 - val_accuracy: 0.5465\n","Epoch 90/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3535 - accuracy: 0.8953 - val_loss: 1.5690 - val_accuracy: 0.5422\n","Epoch 91/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3513 - accuracy: 0.8984 - val_loss: 1.5728 - val_accuracy: 0.5434\n","Epoch 92/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3491 - accuracy: 0.9003 - val_loss: 1.5739 - val_accuracy: 0.5447\n","Epoch 93/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3462 - accuracy: 0.9005 - val_loss: 1.5837 - val_accuracy: 0.5440\n","Epoch 94/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.3443 - accuracy: 0.8997 - val_loss: 1.5929 - val_accuracy: 0.5434\n","Epoch 95/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3421 - accuracy: 0.9014 - val_loss: 1.5965 - val_accuracy: 0.5497\n","Epoch 96/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.3401 - accuracy: 0.9028 - val_loss: 1.5952 - val_accuracy: 0.5434\n","Epoch 97/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3376 - accuracy: 0.9039 - val_loss: 1.6045 - val_accuracy: 0.5403\n","Epoch 98/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3352 - accuracy: 0.9041 - val_loss: 1.6102 - val_accuracy: 0.5384\n","Epoch 99/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.3343 - accuracy: 0.9052 - val_loss: 1.6173 - val_accuracy: 0.5378\n","Epoch 100/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3312 - accuracy: 0.9061 - val_loss: 1.6193 - val_accuracy: 0.5472\n","Epoch 101/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3289 - accuracy: 0.9073 - val_loss: 1.6255 - val_accuracy: 0.5453\n","Epoch 102/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.3270 - accuracy: 0.9080 - val_loss: 1.6315 - val_accuracy: 0.5434\n","Epoch 103/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.3254 - accuracy: 0.9086 - val_loss: 1.6344 - val_accuracy: 0.5409\n","Epoch 104/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3235 - accuracy: 0.9078 - val_loss: 1.6437 - val_accuracy: 0.5390\n","Epoch 105/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3209 - accuracy: 0.9094 - val_loss: 1.6467 - val_accuracy: 0.5428\n","Epoch 106/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3188 - accuracy: 0.9094 - val_loss: 1.6521 - val_accuracy: 0.5415\n","Epoch 107/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3176 - accuracy: 0.9100 - val_loss: 1.6571 - val_accuracy: 0.5415\n","Epoch 108/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3154 - accuracy: 0.9117 - val_loss: 1.6647 - val_accuracy: 0.5403\n","Epoch 109/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3138 - accuracy: 0.9128 - val_loss: 1.6671 - val_accuracy: 0.5347\n","Epoch 110/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.3118 - accuracy: 0.9133 - val_loss: 1.6736 - val_accuracy: 0.5378\n","Epoch 111/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.3099 - accuracy: 0.9137 - val_loss: 1.6768 - val_accuracy: 0.5397\n","Epoch 112/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.3078 - accuracy: 0.9133 - val_loss: 1.6839 - val_accuracy: 0.5415\n","Epoch 113/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.3063 - accuracy: 0.9155 - val_loss: 1.6870 - val_accuracy: 0.5390\n","Epoch 114/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.3043 - accuracy: 0.9159 - val_loss: 1.6918 - val_accuracy: 0.5384\n","Epoch 115/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.3025 - accuracy: 0.9173 - val_loss: 1.7002 - val_accuracy: 0.5378\n","Epoch 116/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.3014 - accuracy: 0.9166 - val_loss: 1.7072 - val_accuracy: 0.5309\n","Epoch 117/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2993 - accuracy: 0.9166 - val_loss: 1.7047 - val_accuracy: 0.5390\n","Epoch 118/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2974 - accuracy: 0.9192 - val_loss: 1.7105 - val_accuracy: 0.5378\n","Epoch 119/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2957 - accuracy: 0.9187 - val_loss: 1.7165 - val_accuracy: 0.5347\n","Epoch 120/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2943 - accuracy: 0.9191 - val_loss: 1.7232 - val_accuracy: 0.5359\n","Epoch 121/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2929 - accuracy: 0.9197 - val_loss: 1.7263 - val_accuracy: 0.5378\n","Epoch 122/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2909 - accuracy: 0.9209 - val_loss: 1.7315 - val_accuracy: 0.5403\n","Epoch 123/200\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.2894 - accuracy: 0.9205 - val_loss: 1.7372 - val_accuracy: 0.5353\n","Epoch 124/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2881 - accuracy: 0.9205 - val_loss: 1.7421 - val_accuracy: 0.5328\n","Epoch 125/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2865 - accuracy: 0.9212 - val_loss: 1.7439 - val_accuracy: 0.5397\n","Epoch 126/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2845 - accuracy: 0.9239 - val_loss: 1.7524 - val_accuracy: 0.5359\n","Epoch 127/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2831 - accuracy: 0.9237 - val_loss: 1.7564 - val_accuracy: 0.5378\n","Epoch 128/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2820 - accuracy: 0.9241 - val_loss: 1.7612 - val_accuracy: 0.5347\n","Epoch 129/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2801 - accuracy: 0.9244 - val_loss: 1.7698 - val_accuracy: 0.5359\n","Epoch 130/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2784 - accuracy: 0.9247 - val_loss: 1.7749 - val_accuracy: 0.5328\n","Epoch 131/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2775 - accuracy: 0.9258 - val_loss: 1.7772 - val_accuracy: 0.5397\n","Epoch 132/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2756 - accuracy: 0.9256 - val_loss: 1.7820 - val_accuracy: 0.5384\n","Epoch 133/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2746 - accuracy: 0.9267 - val_loss: 1.7853 - val_accuracy: 0.5353\n","Epoch 134/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2733 - accuracy: 0.9275 - val_loss: 1.7910 - val_accuracy: 0.5384\n","Epoch 135/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2721 - accuracy: 0.9278 - val_loss: 1.7942 - val_accuracy: 0.5347\n","Epoch 136/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2708 - accuracy: 0.9280 - val_loss: 1.7997 - val_accuracy: 0.5365\n","Epoch 137/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2691 - accuracy: 0.9278 - val_loss: 1.8053 - val_accuracy: 0.5365\n","Epoch 138/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2675 - accuracy: 0.9297 - val_loss: 1.8087 - val_accuracy: 0.5322\n","Epoch 139/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2661 - accuracy: 0.9303 - val_loss: 1.8141 - val_accuracy: 0.5372\n","Epoch 140/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2647 - accuracy: 0.9289 - val_loss: 1.8159 - val_accuracy: 0.5340\n","Epoch 141/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.2639 - accuracy: 0.9298 - val_loss: 1.8212 - val_accuracy: 0.5347\n","Epoch 142/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2621 - accuracy: 0.9308 - val_loss: 1.8269 - val_accuracy: 0.5303\n","Epoch 143/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2609 - accuracy: 0.9300 - val_loss: 1.8315 - val_accuracy: 0.5322\n","Epoch 144/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2598 - accuracy: 0.9316 - val_loss: 1.8352 - val_accuracy: 0.5309\n","Epoch 145/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2583 - accuracy: 0.9314 - val_loss: 1.8398 - val_accuracy: 0.5347\n","Epoch 146/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2571 - accuracy: 0.9328 - val_loss: 1.8470 - val_accuracy: 0.5328\n","Epoch 147/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2560 - accuracy: 0.9322 - val_loss: 1.8461 - val_accuracy: 0.5353\n","Epoch 148/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2550 - accuracy: 0.9327 - val_loss: 1.8541 - val_accuracy: 0.5347\n","Epoch 149/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2534 - accuracy: 0.9341 - val_loss: 1.8586 - val_accuracy: 0.5347\n","Epoch 150/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2525 - accuracy: 0.9331 - val_loss: 1.8593 - val_accuracy: 0.5347\n","Epoch 151/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2509 - accuracy: 0.9344 - val_loss: 1.8681 - val_accuracy: 0.5290\n","Epoch 152/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2497 - accuracy: 0.9347 - val_loss: 1.8741 - val_accuracy: 0.5347\n","Epoch 153/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2489 - accuracy: 0.9350 - val_loss: 1.8762 - val_accuracy: 0.5340\n","Epoch 154/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2476 - accuracy: 0.9358 - val_loss: 1.8806 - val_accuracy: 0.5322\n","Epoch 155/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2464 - accuracy: 0.9361 - val_loss: 1.8848 - val_accuracy: 0.5328\n","Epoch 156/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2452 - accuracy: 0.9367 - val_loss: 1.8931 - val_accuracy: 0.5328\n","Epoch 157/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.2442 - accuracy: 0.9373 - val_loss: 1.8918 - val_accuracy: 0.5322\n","Epoch 158/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2434 - accuracy: 0.9380 - val_loss: 1.9011 - val_accuracy: 0.5303\n","Epoch 159/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.2421 - accuracy: 0.9372 - val_loss: 1.9017 - val_accuracy: 0.5322\n","Epoch 160/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2409 - accuracy: 0.9380 - val_loss: 1.9072 - val_accuracy: 0.5353\n","Epoch 161/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.2399 - accuracy: 0.9389 - val_loss: 1.9085 - val_accuracy: 0.5359\n","Epoch 162/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2386 - accuracy: 0.9394 - val_loss: 1.9141 - val_accuracy: 0.5353\n","Epoch 163/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2378 - accuracy: 0.9392 - val_loss: 1.9172 - val_accuracy: 0.5322\n","Epoch 164/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2369 - accuracy: 0.9392 - val_loss: 1.9234 - val_accuracy: 0.5322\n","Epoch 165/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2359 - accuracy: 0.9403 - val_loss: 1.9274 - val_accuracy: 0.5328\n","Epoch 166/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2348 - accuracy: 0.9397 - val_loss: 1.9317 - val_accuracy: 0.5322\n","Epoch 167/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2341 - accuracy: 0.9403 - val_loss: 1.9346 - val_accuracy: 0.5315\n","Epoch 168/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2326 - accuracy: 0.9402 - val_loss: 1.9432 - val_accuracy: 0.5322\n","Epoch 169/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2316 - accuracy: 0.9414 - val_loss: 1.9452 - val_accuracy: 0.5290\n","Epoch 170/200\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2304 - accuracy: 0.9428 - val_loss: 1.9503 - val_accuracy: 0.5378\n","Epoch 171/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2296 - accuracy: 0.9419 - val_loss: 1.9517 - val_accuracy: 0.5290\n","Epoch 172/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2286 - accuracy: 0.9414 - val_loss: 1.9567 - val_accuracy: 0.5297\n","Epoch 173/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2276 - accuracy: 0.9436 - val_loss: 1.9633 - val_accuracy: 0.5359\n","Epoch 174/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2267 - accuracy: 0.9423 - val_loss: 1.9639 - val_accuracy: 0.5322\n","Epoch 175/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2255 - accuracy: 0.9423 - val_loss: 1.9672 - val_accuracy: 0.5303\n","Epoch 176/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2248 - accuracy: 0.9442 - val_loss: 1.9721 - val_accuracy: 0.5303\n","Epoch 177/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2237 - accuracy: 0.9441 - val_loss: 1.9770 - val_accuracy: 0.5328\n","Epoch 178/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2230 - accuracy: 0.9436 - val_loss: 1.9808 - val_accuracy: 0.5290\n","Epoch 179/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2221 - accuracy: 0.9452 - val_loss: 1.9845 - val_accuracy: 0.5290\n","Epoch 180/200\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.2213 - accuracy: 0.9455 - val_loss: 1.9869 - val_accuracy: 0.5284\n","Epoch 181/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2202 - accuracy: 0.9459 - val_loss: 1.9923 - val_accuracy: 0.5297\n","Epoch 182/200\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2190 - accuracy: 0.9464 - val_loss: 1.9975 - val_accuracy: 0.5297\n","Epoch 183/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.2183 - accuracy: 0.9455 - val_loss: 1.9999 - val_accuracy: 0.5315\n","Epoch 184/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2177 - accuracy: 0.9459 - val_loss: 2.0043 - val_accuracy: 0.5309\n","Epoch 185/200\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.2164 - accuracy: 0.9467 - val_loss: 2.0068 - val_accuracy: 0.5303\n","Epoch 186/200\n","6400/6400 [==============================] - 0s 63us/step - loss: 0.2159 - accuracy: 0.9458 - val_loss: 2.0145 - val_accuracy: 0.5309\n","Epoch 187/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2151 - accuracy: 0.9478 - val_loss: 2.0167 - val_accuracy: 0.5265\n","Epoch 188/200\n","6400/6400 [==============================] - 0s 62us/step - loss: 0.2141 - accuracy: 0.9475 - val_loss: 2.0175 - val_accuracy: 0.5290\n","Epoch 189/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2130 - accuracy: 0.9469 - val_loss: 2.0259 - val_accuracy: 0.5328\n","Epoch 190/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2122 - accuracy: 0.9472 - val_loss: 2.0289 - val_accuracy: 0.5309\n","Epoch 191/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2114 - accuracy: 0.9494 - val_loss: 2.0320 - val_accuracy: 0.5372\n","Epoch 192/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.2108 - accuracy: 0.9480 - val_loss: 2.0344 - val_accuracy: 0.5303\n","Epoch 193/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2097 - accuracy: 0.9480 - val_loss: 2.0375 - val_accuracy: 0.5315\n","Epoch 194/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.2088 - accuracy: 0.9477 - val_loss: 2.0430 - val_accuracy: 0.5253\n","Epoch 195/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.2079 - accuracy: 0.9494 - val_loss: 2.0457 - val_accuracy: 0.5247\n","Epoch 196/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2073 - accuracy: 0.9497 - val_loss: 2.0501 - val_accuracy: 0.5340\n","Epoch 197/200\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.2063 - accuracy: 0.9489 - val_loss: 2.0561 - val_accuracy: 0.5272\n","Epoch 198/200\n","6400/6400 [==============================] - 0s 62us/step - loss: 0.2056 - accuracy: 0.9508 - val_loss: 2.0579 - val_accuracy: 0.5284\n","Epoch 199/200\n","6400/6400 [==============================] - 0s 61us/step - loss: 0.2050 - accuracy: 0.9495 - val_loss: 2.0622 - val_accuracy: 0.5247\n","Epoch 200/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.2040 - accuracy: 0.9517 - val_loss: 2.0635 - val_accuracy: 0.5259\n","1601/1601 [==============================] - 0s 28us/step\n","Loss=2.063492355906613, Acc=0.5259212851524353\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U84BJGZ8tebq","colab_type":"text"},"source":["Con un entranamiento de 200 epocas:\n","\n","```\n","Epoch 200/200\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.2040 - accuracy: 0.9517 - val_loss: 2.0635 - val_accuracy: 0.5259\n","1601/1601 [==============================] - 0s 28us/step\n","Loss=2.063492355906613, Acc=0.5259212851524353\n","```\n","No se mejora el accuracy ni en training ni en validation con lo que realizaremos la predicción sobre el modelo inicial (50 epochs)\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9sHmHbBpt1UA","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592830670819,"user_tz":-120,"elapsed":19150,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"b628c370-517a-4433-d3b5-60fd30a29779"},"source":["# Modelo para el problema de clasificación (función de perdida categorical_crossentropy y metrica accuracy)\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","\n","model = Sequential()\n","model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(5, activation='softmax'))\n","\n","# sparse_categorical_crossentropy es exactamente igual que categorical_crossentropy,\n","# solo que admite enteros en vez de onehot a la entrada\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train,\n","          validation_data=(X_val, y_val),\n","          epochs=50,\n","          batch_size=32)\n","\n","loss, acc = model.evaluate(X_val, y_val)\n","print(f'Loss={loss}, Acc={acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 6400 samples, validate on 1601 samples\n","Epoch 1/50\n","6400/6400 [==============================] - 0s 76us/step - loss: 1.0839 - accuracy: 0.5564 - val_loss: 1.0189 - val_accuracy: 0.5859\n","Epoch 2/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.9879 - accuracy: 0.5987 - val_loss: 0.9951 - val_accuracy: 0.6115\n","Epoch 3/50\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.9578 - accuracy: 0.6097 - val_loss: 0.9827 - val_accuracy: 0.6196\n","Epoch 4/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.9312 - accuracy: 0.6264 - val_loss: 0.9934 - val_accuracy: 0.6177\n","Epoch 5/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.9164 - accuracy: 0.6331 - val_loss: 0.9882 - val_accuracy: 0.6227\n","Epoch 6/50\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.8929 - accuracy: 0.6398 - val_loss: 0.9943 - val_accuracy: 0.6134\n","Epoch 7/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.8640 - accuracy: 0.6519 - val_loss: 1.0299 - val_accuracy: 0.6109\n","Epoch 8/50\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.8359 - accuracy: 0.6664 - val_loss: 1.0158 - val_accuracy: 0.6084\n","Epoch 9/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.8071 - accuracy: 0.6781 - val_loss: 1.0664 - val_accuracy: 0.5715\n","Epoch 10/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.7768 - accuracy: 0.6966 - val_loss: 1.0690 - val_accuracy: 0.6115\n","Epoch 11/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.7375 - accuracy: 0.7080 - val_loss: 1.0917 - val_accuracy: 0.6052\n","Epoch 12/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.6887 - accuracy: 0.7362 - val_loss: 1.1241 - val_accuracy: 0.5790\n","Epoch 13/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.6459 - accuracy: 0.7542 - val_loss: 1.1790 - val_accuracy: 0.5828\n","Epoch 14/50\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.6118 - accuracy: 0.7698 - val_loss: 1.2194 - val_accuracy: 0.5903\n","Epoch 15/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.5598 - accuracy: 0.7975 - val_loss: 1.3075 - val_accuracy: 0.5540\n","Epoch 16/50\n","6400/6400 [==============================] - 0s 59us/step - loss: 0.5216 - accuracy: 0.8094 - val_loss: 1.3308 - val_accuracy: 0.5659\n","Epoch 17/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.4729 - accuracy: 0.8359 - val_loss: 1.4620 - val_accuracy: 0.5503\n","Epoch 18/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.4345 - accuracy: 0.8467 - val_loss: 1.5208 - val_accuracy: 0.5347\n","Epoch 19/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.4015 - accuracy: 0.8644 - val_loss: 1.5592 - val_accuracy: 0.5528\n","Epoch 20/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.3580 - accuracy: 0.8800 - val_loss: 1.6569 - val_accuracy: 0.5584\n","Epoch 21/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.3275 - accuracy: 0.8947 - val_loss: 1.7504 - val_accuracy: 0.5390\n","Epoch 22/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2981 - accuracy: 0.9080 - val_loss: 1.8702 - val_accuracy: 0.5415\n","Epoch 23/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.2619 - accuracy: 0.9234 - val_loss: 1.9044 - val_accuracy: 0.5259\n","Epoch 24/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.2283 - accuracy: 0.9366 - val_loss: 2.0186 - val_accuracy: 0.5403\n","Epoch 25/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.2179 - accuracy: 0.9384 - val_loss: 2.0758 - val_accuracy: 0.5178\n","Epoch 26/50\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.1845 - accuracy: 0.9527 - val_loss: 2.1786 - val_accuracy: 0.5328\n","Epoch 27/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.1611 - accuracy: 0.9633 - val_loss: 2.3207 - val_accuracy: 0.5253\n","Epoch 28/50\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.1460 - accuracy: 0.9634 - val_loss: 2.4236 - val_accuracy: 0.5265\n","Epoch 29/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.1353 - accuracy: 0.9691 - val_loss: 2.5274 - val_accuracy: 0.5434\n","Epoch 30/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.1284 - accuracy: 0.9709 - val_loss: 2.5373 - val_accuracy: 0.5215\n","Epoch 31/50\n","6400/6400 [==============================] - 0s 57us/step - loss: 0.1066 - accuracy: 0.9775 - val_loss: 2.6723 - val_accuracy: 0.5384\n","Epoch 32/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.1005 - accuracy: 0.9797 - val_loss: 2.7528 - val_accuracy: 0.5359\n","Epoch 33/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.0869 - accuracy: 0.9841 - val_loss: 2.8474 - val_accuracy: 0.5222\n","Epoch 34/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.0813 - accuracy: 0.9858 - val_loss: 2.9253 - val_accuracy: 0.5228\n","Epoch 35/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.0721 - accuracy: 0.9858 - val_loss: 2.9818 - val_accuracy: 0.5284\n","Epoch 36/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.0750 - accuracy: 0.9861 - val_loss: 3.0931 - val_accuracy: 0.5247\n","Epoch 37/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.0710 - accuracy: 0.9869 - val_loss: 3.1607 - val_accuracy: 0.5359\n","Epoch 38/50\n","6400/6400 [==============================] - 0s 53us/step - loss: 0.0603 - accuracy: 0.9895 - val_loss: 3.2240 - val_accuracy: 0.5084\n","Epoch 39/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.0553 - accuracy: 0.9897 - val_loss: 3.4534 - val_accuracy: 0.5340\n","Epoch 40/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.0637 - accuracy: 0.9880 - val_loss: 3.4401 - val_accuracy: 0.4984\n","Epoch 41/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.0665 - accuracy: 0.9855 - val_loss: 3.5248 - val_accuracy: 0.5309\n","Epoch 42/50\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.0592 - accuracy: 0.9883 - val_loss: 3.5546 - val_accuracy: 0.5409\n","Epoch 43/50\n","6400/6400 [==============================] - 0s 53us/step - loss: 0.0495 - accuracy: 0.9912 - val_loss: 3.5487 - val_accuracy: 0.5147\n","Epoch 44/50\n","6400/6400 [==============================] - 0s 55us/step - loss: 0.0535 - accuracy: 0.9894 - val_loss: 3.6667 - val_accuracy: 0.5397\n","Epoch 45/50\n","6400/6400 [==============================] - 0s 60us/step - loss: 0.0468 - accuracy: 0.9914 - val_loss: 3.7856 - val_accuracy: 0.5284\n","Epoch 46/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.0511 - accuracy: 0.9891 - val_loss: 3.7740 - val_accuracy: 0.5447\n","Epoch 47/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.0427 - accuracy: 0.9931 - val_loss: 3.8323 - val_accuracy: 0.5359\n","Epoch 48/50\n","6400/6400 [==============================] - 0s 56us/step - loss: 0.0401 - accuracy: 0.9920 - val_loss: 3.7138 - val_accuracy: 0.5340\n","Epoch 49/50\n","6400/6400 [==============================] - 0s 54us/step - loss: 0.0595 - accuracy: 0.9850 - val_loss: 3.9625 - val_accuracy: 0.5322\n","Epoch 50/50\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.0528 - accuracy: 0.9873 - val_loss: 3.6753 - val_accuracy: 0.5159\n","1601/1601 [==============================] - 0s 23us/step\n","Loss=3.6752615484276987, Acc=0.5159275531768799\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eePOCqdht1UK"},"source":["Accuracy obtenido en train es aproximadamente de un 98.73% y un 51.59% en validación, existe overfitting.\n","\n","```\n","Epoch 50/50\n","6400/6400 [==============================] - 0s 58us/step - loss: 0.0528 - accuracy: 0.9873 - val_loss: 3.6753 - val_accuracy: 0.5159\n","1601/1601 [==============================] - 0s 23us/step\n","Loss=3.6752615484276987, Acc=0.5159275531768799\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"niftkwVvugR6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592830708862,"user_tz":-120,"elapsed":570,"user":{"displayName":"Olga Alvaro Melero","photoUrl":"","userId":"16889773465311788243"}},"outputId":"348543d7-00b4-426e-e763-818d3dcf288e"},"source":["# Evaluamos sobre el conjunto de test\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f'Loss={loss}, Acc={acc}')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3941/3941 [==============================] - 0s 24us/step\n","Loss=3.5573130341176302, Acc=0.5062167048454285\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tbIAxPENu7eQ","colab_type":"text"},"source":["Se obtiene un accuracy del 50% en test, que es un mal resultado ya que existe overfitting y el modelo no está generalizando bien."]}]}